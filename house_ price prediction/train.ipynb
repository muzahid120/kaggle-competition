{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 585,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns',None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>LotConfig</th>\n",
       "      <th>LandSlope</th>\n",
       "      <th>Neighborhood</th>\n",
       "      <th>Condition1</th>\n",
       "      <th>Condition2</th>\n",
       "      <th>BldgType</th>\n",
       "      <th>HouseStyle</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>RoofStyle</th>\n",
       "      <th>RoofMatl</th>\n",
       "      <th>Exterior1st</th>\n",
       "      <th>Exterior2nd</th>\n",
       "      <th>MasVnrType</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>ExterQual</th>\n",
       "      <th>ExterCond</th>\n",
       "      <th>Foundation</th>\n",
       "      <th>BsmtQual</th>\n",
       "      <th>BsmtCond</th>\n",
       "      <th>BsmtExposure</th>\n",
       "      <th>BsmtFinType1</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinType2</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>BsmtUnfSF</th>\n",
       "      <th>TotalBsmtSF</th>\n",
       "      <th>Heating</th>\n",
       "      <th>HeatingQC</th>\n",
       "      <th>CentralAir</th>\n",
       "      <th>Electrical</th>\n",
       "      <th>1stFlrSF</th>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <th>LowQualFinSF</th>\n",
       "      <th>GrLivArea</th>\n",
       "      <th>BsmtFullBath</th>\n",
       "      <th>BsmtHalfBath</th>\n",
       "      <th>FullBath</th>\n",
       "      <th>HalfBath</th>\n",
       "      <th>BedroomAbvGr</th>\n",
       "      <th>KitchenAbvGr</th>\n",
       "      <th>KitchenQual</th>\n",
       "      <th>TotRmsAbvGrd</th>\n",
       "      <th>Functional</th>\n",
       "      <th>Fireplaces</th>\n",
       "      <th>FireplaceQu</th>\n",
       "      <th>GarageType</th>\n",
       "      <th>GarageYrBlt</th>\n",
       "      <th>GarageFinish</th>\n",
       "      <th>GarageCars</th>\n",
       "      <th>GarageArea</th>\n",
       "      <th>GarageQual</th>\n",
       "      <th>GarageCond</th>\n",
       "      <th>PavedDrive</th>\n",
       "      <th>WoodDeckSF</th>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>CollgCr</td>\n",
       "      <td>Norm</td>\n",
       "      <td>Norm</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>2Story</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2003</td>\n",
       "      <td>2003</td>\n",
       "      <td>Gable</td>\n",
       "      <td>CompShg</td>\n",
       "      <td>VinylSd</td>\n",
       "      <td>VinylSd</td>\n",
       "      <td>BrkFace</td>\n",
       "      <td>196.0</td>\n",
       "      <td>Gd</td>\n",
       "      <td>TA</td>\n",
       "      <td>PConc</td>\n",
       "      <td>Gd</td>\n",
       "      <td>TA</td>\n",
       "      <td>No</td>\n",
       "      <td>GLQ</td>\n",
       "      <td>706</td>\n",
       "      <td>Unf</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>856</td>\n",
       "      <td>GasA</td>\n",
       "      <td>Ex</td>\n",
       "      <td>Y</td>\n",
       "      <td>SBrkr</td>\n",
       "      <td>856</td>\n",
       "      <td>854</td>\n",
       "      <td>0</td>\n",
       "      <td>1710</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Gd</td>\n",
       "      <td>8</td>\n",
       "      <td>Typ</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Attchd</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>RFn</td>\n",
       "      <td>2</td>\n",
       "      <td>548</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>Veenker</td>\n",
       "      <td>Feedr</td>\n",
       "      <td>Norm</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>1Story</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>1976</td>\n",
       "      <td>1976</td>\n",
       "      <td>Gable</td>\n",
       "      <td>CompShg</td>\n",
       "      <td>MetalSd</td>\n",
       "      <td>MetalSd</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>CBlock</td>\n",
       "      <td>Gd</td>\n",
       "      <td>TA</td>\n",
       "      <td>Gd</td>\n",
       "      <td>ALQ</td>\n",
       "      <td>978</td>\n",
       "      <td>Unf</td>\n",
       "      <td>0</td>\n",
       "      <td>284</td>\n",
       "      <td>1262</td>\n",
       "      <td>GasA</td>\n",
       "      <td>Ex</td>\n",
       "      <td>Y</td>\n",
       "      <td>SBrkr</td>\n",
       "      <td>1262</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1262</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>TA</td>\n",
       "      <td>6</td>\n",
       "      <td>Typ</td>\n",
       "      <td>1</td>\n",
       "      <td>TA</td>\n",
       "      <td>Attchd</td>\n",
       "      <td>1976.0</td>\n",
       "      <td>RFn</td>\n",
       "      <td>2</td>\n",
       "      <td>460</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>298</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>CollgCr</td>\n",
       "      <td>Norm</td>\n",
       "      <td>Norm</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>2Story</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2001</td>\n",
       "      <td>2002</td>\n",
       "      <td>Gable</td>\n",
       "      <td>CompShg</td>\n",
       "      <td>VinylSd</td>\n",
       "      <td>VinylSd</td>\n",
       "      <td>BrkFace</td>\n",
       "      <td>162.0</td>\n",
       "      <td>Gd</td>\n",
       "      <td>TA</td>\n",
       "      <td>PConc</td>\n",
       "      <td>Gd</td>\n",
       "      <td>TA</td>\n",
       "      <td>Mn</td>\n",
       "      <td>GLQ</td>\n",
       "      <td>486</td>\n",
       "      <td>Unf</td>\n",
       "      <td>0</td>\n",
       "      <td>434</td>\n",
       "      <td>920</td>\n",
       "      <td>GasA</td>\n",
       "      <td>Ex</td>\n",
       "      <td>Y</td>\n",
       "      <td>SBrkr</td>\n",
       "      <td>920</td>\n",
       "      <td>866</td>\n",
       "      <td>0</td>\n",
       "      <td>1786</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Gd</td>\n",
       "      <td>6</td>\n",
       "      <td>Typ</td>\n",
       "      <td>1</td>\n",
       "      <td>TA</td>\n",
       "      <td>Attchd</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>RFn</td>\n",
       "      <td>2</td>\n",
       "      <td>608</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Corner</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>Crawfor</td>\n",
       "      <td>Norm</td>\n",
       "      <td>Norm</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>2Story</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1915</td>\n",
       "      <td>1970</td>\n",
       "      <td>Gable</td>\n",
       "      <td>CompShg</td>\n",
       "      <td>Wd Sdng</td>\n",
       "      <td>Wd Shng</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>BrkTil</td>\n",
       "      <td>TA</td>\n",
       "      <td>Gd</td>\n",
       "      <td>No</td>\n",
       "      <td>ALQ</td>\n",
       "      <td>216</td>\n",
       "      <td>Unf</td>\n",
       "      <td>0</td>\n",
       "      <td>540</td>\n",
       "      <td>756</td>\n",
       "      <td>GasA</td>\n",
       "      <td>Gd</td>\n",
       "      <td>Y</td>\n",
       "      <td>SBrkr</td>\n",
       "      <td>961</td>\n",
       "      <td>756</td>\n",
       "      <td>0</td>\n",
       "      <td>1717</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Gd</td>\n",
       "      <td>7</td>\n",
       "      <td>Typ</td>\n",
       "      <td>1</td>\n",
       "      <td>Gd</td>\n",
       "      <td>Detchd</td>\n",
       "      <td>1998.0</td>\n",
       "      <td>Unf</td>\n",
       "      <td>3</td>\n",
       "      <td>642</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>272</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>NoRidge</td>\n",
       "      <td>Norm</td>\n",
       "      <td>Norm</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>2Story</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>Gable</td>\n",
       "      <td>CompShg</td>\n",
       "      <td>VinylSd</td>\n",
       "      <td>VinylSd</td>\n",
       "      <td>BrkFace</td>\n",
       "      <td>350.0</td>\n",
       "      <td>Gd</td>\n",
       "      <td>TA</td>\n",
       "      <td>PConc</td>\n",
       "      <td>Gd</td>\n",
       "      <td>TA</td>\n",
       "      <td>Av</td>\n",
       "      <td>GLQ</td>\n",
       "      <td>655</td>\n",
       "      <td>Unf</td>\n",
       "      <td>0</td>\n",
       "      <td>490</td>\n",
       "      <td>1145</td>\n",
       "      <td>GasA</td>\n",
       "      <td>Ex</td>\n",
       "      <td>Y</td>\n",
       "      <td>SBrkr</td>\n",
       "      <td>1145</td>\n",
       "      <td>1053</td>\n",
       "      <td>0</td>\n",
       "      <td>2198</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Gd</td>\n",
       "      <td>9</td>\n",
       "      <td>Typ</td>\n",
       "      <td>1</td>\n",
       "      <td>TA</td>\n",
       "      <td>Attchd</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>RFn</td>\n",
       "      <td>3</td>\n",
       "      <td>836</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>192</td>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
       "1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
       "2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
       "3   4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
       "4   5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
       "\n",
       "  LandContour Utilities LotConfig LandSlope Neighborhood Condition1  \\\n",
       "0         Lvl    AllPub    Inside       Gtl      CollgCr       Norm   \n",
       "1         Lvl    AllPub       FR2       Gtl      Veenker      Feedr   \n",
       "2         Lvl    AllPub    Inside       Gtl      CollgCr       Norm   \n",
       "3         Lvl    AllPub    Corner       Gtl      Crawfor       Norm   \n",
       "4         Lvl    AllPub       FR2       Gtl      NoRidge       Norm   \n",
       "\n",
       "  Condition2 BldgType HouseStyle  OverallQual  OverallCond  YearBuilt  \\\n",
       "0       Norm     1Fam     2Story            7            5       2003   \n",
       "1       Norm     1Fam     1Story            6            8       1976   \n",
       "2       Norm     1Fam     2Story            7            5       2001   \n",
       "3       Norm     1Fam     2Story            7            5       1915   \n",
       "4       Norm     1Fam     2Story            8            5       2000   \n",
       "\n",
       "   YearRemodAdd RoofStyle RoofMatl Exterior1st Exterior2nd MasVnrType  \\\n",
       "0          2003     Gable  CompShg     VinylSd     VinylSd    BrkFace   \n",
       "1          1976     Gable  CompShg     MetalSd     MetalSd        NaN   \n",
       "2          2002     Gable  CompShg     VinylSd     VinylSd    BrkFace   \n",
       "3          1970     Gable  CompShg     Wd Sdng     Wd Shng        NaN   \n",
       "4          2000     Gable  CompShg     VinylSd     VinylSd    BrkFace   \n",
       "\n",
       "   MasVnrArea ExterQual ExterCond Foundation BsmtQual BsmtCond BsmtExposure  \\\n",
       "0       196.0        Gd        TA      PConc       Gd       TA           No   \n",
       "1         0.0        TA        TA     CBlock       Gd       TA           Gd   \n",
       "2       162.0        Gd        TA      PConc       Gd       TA           Mn   \n",
       "3         0.0        TA        TA     BrkTil       TA       Gd           No   \n",
       "4       350.0        Gd        TA      PConc       Gd       TA           Av   \n",
       "\n",
       "  BsmtFinType1  BsmtFinSF1 BsmtFinType2  BsmtFinSF2  BsmtUnfSF  TotalBsmtSF  \\\n",
       "0          GLQ         706          Unf           0        150          856   \n",
       "1          ALQ         978          Unf           0        284         1262   \n",
       "2          GLQ         486          Unf           0        434          920   \n",
       "3          ALQ         216          Unf           0        540          756   \n",
       "4          GLQ         655          Unf           0        490         1145   \n",
       "\n",
       "  Heating HeatingQC CentralAir Electrical  1stFlrSF  2ndFlrSF  LowQualFinSF  \\\n",
       "0    GasA        Ex          Y      SBrkr       856       854             0   \n",
       "1    GasA        Ex          Y      SBrkr      1262         0             0   \n",
       "2    GasA        Ex          Y      SBrkr       920       866             0   \n",
       "3    GasA        Gd          Y      SBrkr       961       756             0   \n",
       "4    GasA        Ex          Y      SBrkr      1145      1053             0   \n",
       "\n",
       "   GrLivArea  BsmtFullBath  BsmtHalfBath  FullBath  HalfBath  BedroomAbvGr  \\\n",
       "0       1710             1             0         2         1             3   \n",
       "1       1262             0             1         2         0             3   \n",
       "2       1786             1             0         2         1             3   \n",
       "3       1717             1             0         1         0             3   \n",
       "4       2198             1             0         2         1             4   \n",
       "\n",
       "   KitchenAbvGr KitchenQual  TotRmsAbvGrd Functional  Fireplaces FireplaceQu  \\\n",
       "0             1          Gd             8        Typ           0         NaN   \n",
       "1             1          TA             6        Typ           1          TA   \n",
       "2             1          Gd             6        Typ           1          TA   \n",
       "3             1          Gd             7        Typ           1          Gd   \n",
       "4             1          Gd             9        Typ           1          TA   \n",
       "\n",
       "  GarageType  GarageYrBlt GarageFinish  GarageCars  GarageArea GarageQual  \\\n",
       "0     Attchd       2003.0          RFn           2         548         TA   \n",
       "1     Attchd       1976.0          RFn           2         460         TA   \n",
       "2     Attchd       2001.0          RFn           2         608         TA   \n",
       "3     Detchd       1998.0          Unf           3         642         TA   \n",
       "4     Attchd       2000.0          RFn           3         836         TA   \n",
       "\n",
       "  GarageCond PavedDrive  WoodDeckSF  OpenPorchSF  EnclosedPorch  3SsnPorch  \\\n",
       "0         TA          Y           0           61              0          0   \n",
       "1         TA          Y         298            0              0          0   \n",
       "2         TA          Y           0           42              0          0   \n",
       "3         TA          Y           0           35            272          0   \n",
       "4         TA          Y         192           84              0          0   \n",
       "\n",
       "   ScreenPorch  PoolArea PoolQC Fence MiscFeature  MiscVal  MoSold  YrSold  \\\n",
       "0            0         0    NaN   NaN         NaN        0       2    2008   \n",
       "1            0         0    NaN   NaN         NaN        0       5    2007   \n",
       "2            0         0    NaN   NaN         NaN        0       9    2008   \n",
       "3            0         0    NaN   NaN         NaN        0       2    2006   \n",
       "4            0         0    NaN   NaN         NaN        0      12    2008   \n",
       "\n",
       "  SaleType SaleCondition  SalePrice  \n",
       "0       WD        Normal     208500  \n",
       "1       WD        Normal     181500  \n",
       "2       WD        Normal     223500  \n",
       "3       WD       Abnorml     140000  \n",
       "4       WD        Normal     250000  "
      ]
     },
     "execution_count": 587,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(r'C:\\Users\\SDS\\Documents\\house price\\train.csv')\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1460 entries, 0 to 1459\n",
      "Data columns (total 81 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   Id             1460 non-null   int64  \n",
      " 1   MSSubClass     1460 non-null   int64  \n",
      " 2   MSZoning       1460 non-null   object \n",
      " 3   LotFrontage    1201 non-null   float64\n",
      " 4   LotArea        1460 non-null   int64  \n",
      " 5   Street         1460 non-null   object \n",
      " 6   Alley          91 non-null     object \n",
      " 7   LotShape       1460 non-null   object \n",
      " 8   LandContour    1460 non-null   object \n",
      " 9   Utilities      1460 non-null   object \n",
      " 10  LotConfig      1460 non-null   object \n",
      " 11  LandSlope      1460 non-null   object \n",
      " 12  Neighborhood   1460 non-null   object \n",
      " 13  Condition1     1460 non-null   object \n",
      " 14  Condition2     1460 non-null   object \n",
      " 15  BldgType       1460 non-null   object \n",
      " 16  HouseStyle     1460 non-null   object \n",
      " 17  OverallQual    1460 non-null   int64  \n",
      " 18  OverallCond    1460 non-null   int64  \n",
      " 19  YearBuilt      1460 non-null   int64  \n",
      " 20  YearRemodAdd   1460 non-null   int64  \n",
      " 21  RoofStyle      1460 non-null   object \n",
      " 22  RoofMatl       1460 non-null   object \n",
      " 23  Exterior1st    1460 non-null   object \n",
      " 24  Exterior2nd    1460 non-null   object \n",
      " 25  MasVnrType     588 non-null    object \n",
      " 26  MasVnrArea     1452 non-null   float64\n",
      " 27  ExterQual      1460 non-null   object \n",
      " 28  ExterCond      1460 non-null   object \n",
      " 29  Foundation     1460 non-null   object \n",
      " 30  BsmtQual       1423 non-null   object \n",
      " 31  BsmtCond       1423 non-null   object \n",
      " 32  BsmtExposure   1422 non-null   object \n",
      " 33  BsmtFinType1   1423 non-null   object \n",
      " 34  BsmtFinSF1     1460 non-null   int64  \n",
      " 35  BsmtFinType2   1422 non-null   object \n",
      " 36  BsmtFinSF2     1460 non-null   int64  \n",
      " 37  BsmtUnfSF      1460 non-null   int64  \n",
      " 38  TotalBsmtSF    1460 non-null   int64  \n",
      " 39  Heating        1460 non-null   object \n",
      " 40  HeatingQC      1460 non-null   object \n",
      " 41  CentralAir     1460 non-null   object \n",
      " 42  Electrical     1459 non-null   object \n",
      " 43  1stFlrSF       1460 non-null   int64  \n",
      " 44  2ndFlrSF       1460 non-null   int64  \n",
      " 45  LowQualFinSF   1460 non-null   int64  \n",
      " 46  GrLivArea      1460 non-null   int64  \n",
      " 47  BsmtFullBath   1460 non-null   int64  \n",
      " 48  BsmtHalfBath   1460 non-null   int64  \n",
      " 49  FullBath       1460 non-null   int64  \n",
      " 50  HalfBath       1460 non-null   int64  \n",
      " 51  BedroomAbvGr   1460 non-null   int64  \n",
      " 52  KitchenAbvGr   1460 non-null   int64  \n",
      " 53  KitchenQual    1460 non-null   object \n",
      " 54  TotRmsAbvGrd   1460 non-null   int64  \n",
      " 55  Functional     1460 non-null   object \n",
      " 56  Fireplaces     1460 non-null   int64  \n",
      " 57  FireplaceQu    770 non-null    object \n",
      " 58  GarageType     1379 non-null   object \n",
      " 59  GarageYrBlt    1379 non-null   float64\n",
      " 60  GarageFinish   1379 non-null   object \n",
      " 61  GarageCars     1460 non-null   int64  \n",
      " 62  GarageArea     1460 non-null   int64  \n",
      " 63  GarageQual     1379 non-null   object \n",
      " 64  GarageCond     1379 non-null   object \n",
      " 65  PavedDrive     1460 non-null   object \n",
      " 66  WoodDeckSF     1460 non-null   int64  \n",
      " 67  OpenPorchSF    1460 non-null   int64  \n",
      " 68  EnclosedPorch  1460 non-null   int64  \n",
      " 69  3SsnPorch      1460 non-null   int64  \n",
      " 70  ScreenPorch    1460 non-null   int64  \n",
      " 71  PoolArea       1460 non-null   int64  \n",
      " 72  PoolQC         7 non-null      object \n",
      " 73  Fence          281 non-null    object \n",
      " 74  MiscFeature    54 non-null     object \n",
      " 75  MiscVal        1460 non-null   int64  \n",
      " 76  MoSold         1460 non-null   int64  \n",
      " 77  YrSold         1460 non-null   int64  \n",
      " 78  SaleType       1460 non-null   object \n",
      " 79  SaleCondition  1460 non-null   object \n",
      " 80  SalePrice      1460 non-null   int64  \n",
      "dtypes: float64(3), int64(35), object(43)\n",
      "memory usage: 924.0+ KB\n"
     ]
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "df.info(all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Id                 0\n",
       "MSSubClass         0\n",
       "MSZoning           0\n",
       "LotFrontage      259\n",
       "LotArea            0\n",
       "                ... \n",
       "MoSold             0\n",
       "YrSold             0\n",
       "SaleType           0\n",
       "SaleCondition      0\n",
       "SalePrice          0\n",
       "Length: 81, dtype: int64"
      ]
     },
     "execution_count": 590,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 591,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(df.isnull(),yticklabels=False,cbar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Id                0.000000\n",
       "MSSubClass        0.000000\n",
       "MSZoning          0.000000\n",
       "LotFrontage      17.739726\n",
       "LotArea           0.000000\n",
       "                   ...    \n",
       "MoSold            0.000000\n",
       "YrSold            0.000000\n",
       "SaleType          0.000000\n",
       "SaleCondition     0.000000\n",
       "SalePrice         0.000000\n",
       "Length: 81, dtype: float64"
      ]
     },
     "execution_count": 592,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().mean()*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill missing value \n",
    "df['LotFrontage']=df['LotFrontage'].fillna(df['LotFrontage'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df.drop(columns=['Alley','MasVnrType','FireplaceQu','PoolQC','Fence','MiscFeature'],inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['MasVnrArea']=df['MasVnrArea'].fillna(df['MasVnrArea'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['BsmtQual']=df['BsmtQual'].fillna(df['BsmtQual'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['BsmtCond']=df['BsmtCond'].fillna(df['BsmtCond'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 600,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['BsmtExposure']=df['BsmtExposure'].fillna(df['BsmtExposure'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['BsmtFinType1']=df['BsmtFinType1'].fillna(df['BsmtFinType1'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['BsmtFinType2']=df['BsmtFinType2'].fillna(df['BsmtFinType2'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Electrical']=df['Electrical'].fillna(df['Electrical'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['GarageType']=df['GarageType'].fillna(df['GarageType'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['GarageYrBlt']=df['GarageYrBlt'].fillna(df['GarageYrBlt'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['GarageFinish']=df['GarageFinish'].fillna(df['GarageFinish'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['GarageQual']=df['GarageQual'].fillna(df['GarageQual'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['GarageCond']=df['GarageCond'].fillna(df['GarageCond'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['Id'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1460, 74)"
      ]
     },
     "execution_count": 615,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1459, 73)"
      ]
     },
     "execution_count": 616,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#combine test data\n",
    "test_df=pd.read_csv('formulated_test_data.csv')\n",
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>LotConfig</th>\n",
       "      <th>LandSlope</th>\n",
       "      <th>Neighborhood</th>\n",
       "      <th>Condition1</th>\n",
       "      <th>Condition2</th>\n",
       "      <th>BldgType</th>\n",
       "      <th>HouseStyle</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>RoofStyle</th>\n",
       "      <th>RoofMatl</th>\n",
       "      <th>Exterior1st</th>\n",
       "      <th>Exterior2nd</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>ExterQual</th>\n",
       "      <th>ExterCond</th>\n",
       "      <th>Foundation</th>\n",
       "      <th>BsmtQual</th>\n",
       "      <th>BsmtCond</th>\n",
       "      <th>BsmtExposure</th>\n",
       "      <th>BsmtFinType1</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinType2</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>BsmtUnfSF</th>\n",
       "      <th>TotalBsmtSF</th>\n",
       "      <th>Heating</th>\n",
       "      <th>HeatingQC</th>\n",
       "      <th>CentralAir</th>\n",
       "      <th>Electrical</th>\n",
       "      <th>1stFlrSF</th>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <th>LowQualFinSF</th>\n",
       "      <th>GrLivArea</th>\n",
       "      <th>BsmtFullBath</th>\n",
       "      <th>BsmtHalfBath</th>\n",
       "      <th>FullBath</th>\n",
       "      <th>HalfBath</th>\n",
       "      <th>BedroomAbvGr</th>\n",
       "      <th>KitchenAbvGr</th>\n",
       "      <th>KitchenQual</th>\n",
       "      <th>TotRmsAbvGrd</th>\n",
       "      <th>Functional</th>\n",
       "      <th>Fireplaces</th>\n",
       "      <th>GarageType</th>\n",
       "      <th>GarageYrBlt</th>\n",
       "      <th>GarageFinish</th>\n",
       "      <th>GarageCars</th>\n",
       "      <th>GarageArea</th>\n",
       "      <th>GarageQual</th>\n",
       "      <th>GarageCond</th>\n",
       "      <th>PavedDrive</th>\n",
       "      <th>WoodDeckSF</th>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>CollgCr</td>\n",
       "      <td>Norm</td>\n",
       "      <td>Norm</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>2Story</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2003</td>\n",
       "      <td>2003</td>\n",
       "      <td>Gable</td>\n",
       "      <td>CompShg</td>\n",
       "      <td>VinylSd</td>\n",
       "      <td>VinylSd</td>\n",
       "      <td>196.0</td>\n",
       "      <td>Gd</td>\n",
       "      <td>TA</td>\n",
       "      <td>PConc</td>\n",
       "      <td>Gd</td>\n",
       "      <td>TA</td>\n",
       "      <td>No</td>\n",
       "      <td>GLQ</td>\n",
       "      <td>706.0</td>\n",
       "      <td>Unf</td>\n",
       "      <td>0.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>856.0</td>\n",
       "      <td>GasA</td>\n",
       "      <td>Ex</td>\n",
       "      <td>Y</td>\n",
       "      <td>SBrkr</td>\n",
       "      <td>856</td>\n",
       "      <td>854</td>\n",
       "      <td>0</td>\n",
       "      <td>1710</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Gd</td>\n",
       "      <td>8</td>\n",
       "      <td>Typ</td>\n",
       "      <td>0</td>\n",
       "      <td>Attchd</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>RFn</td>\n",
       "      <td>2.0</td>\n",
       "      <td>548.0</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>Veenker</td>\n",
       "      <td>Feedr</td>\n",
       "      <td>Norm</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>1Story</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>1976</td>\n",
       "      <td>1976</td>\n",
       "      <td>Gable</td>\n",
       "      <td>CompShg</td>\n",
       "      <td>MetalSd</td>\n",
       "      <td>MetalSd</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>CBlock</td>\n",
       "      <td>Gd</td>\n",
       "      <td>TA</td>\n",
       "      <td>Gd</td>\n",
       "      <td>ALQ</td>\n",
       "      <td>978.0</td>\n",
       "      <td>Unf</td>\n",
       "      <td>0.0</td>\n",
       "      <td>284.0</td>\n",
       "      <td>1262.0</td>\n",
       "      <td>GasA</td>\n",
       "      <td>Ex</td>\n",
       "      <td>Y</td>\n",
       "      <td>SBrkr</td>\n",
       "      <td>1262</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1262</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>TA</td>\n",
       "      <td>6</td>\n",
       "      <td>Typ</td>\n",
       "      <td>1</td>\n",
       "      <td>Attchd</td>\n",
       "      <td>1976.0</td>\n",
       "      <td>RFn</td>\n",
       "      <td>2.0</td>\n",
       "      <td>460.0</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>298</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>CollgCr</td>\n",
       "      <td>Norm</td>\n",
       "      <td>Norm</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>2Story</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2001</td>\n",
       "      <td>2002</td>\n",
       "      <td>Gable</td>\n",
       "      <td>CompShg</td>\n",
       "      <td>VinylSd</td>\n",
       "      <td>VinylSd</td>\n",
       "      <td>162.0</td>\n",
       "      <td>Gd</td>\n",
       "      <td>TA</td>\n",
       "      <td>PConc</td>\n",
       "      <td>Gd</td>\n",
       "      <td>TA</td>\n",
       "      <td>Mn</td>\n",
       "      <td>GLQ</td>\n",
       "      <td>486.0</td>\n",
       "      <td>Unf</td>\n",
       "      <td>0.0</td>\n",
       "      <td>434.0</td>\n",
       "      <td>920.0</td>\n",
       "      <td>GasA</td>\n",
       "      <td>Ex</td>\n",
       "      <td>Y</td>\n",
       "      <td>SBrkr</td>\n",
       "      <td>920</td>\n",
       "      <td>866</td>\n",
       "      <td>0</td>\n",
       "      <td>1786</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Gd</td>\n",
       "      <td>6</td>\n",
       "      <td>Typ</td>\n",
       "      <td>1</td>\n",
       "      <td>Attchd</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>RFn</td>\n",
       "      <td>2.0</td>\n",
       "      <td>608.0</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Corner</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>Crawfor</td>\n",
       "      <td>Norm</td>\n",
       "      <td>Norm</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>2Story</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1915</td>\n",
       "      <td>1970</td>\n",
       "      <td>Gable</td>\n",
       "      <td>CompShg</td>\n",
       "      <td>Wd Sdng</td>\n",
       "      <td>Wd Shng</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>BrkTil</td>\n",
       "      <td>TA</td>\n",
       "      <td>Gd</td>\n",
       "      <td>No</td>\n",
       "      <td>ALQ</td>\n",
       "      <td>216.0</td>\n",
       "      <td>Unf</td>\n",
       "      <td>0.0</td>\n",
       "      <td>540.0</td>\n",
       "      <td>756.0</td>\n",
       "      <td>GasA</td>\n",
       "      <td>Gd</td>\n",
       "      <td>Y</td>\n",
       "      <td>SBrkr</td>\n",
       "      <td>961</td>\n",
       "      <td>756</td>\n",
       "      <td>0</td>\n",
       "      <td>1717</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Gd</td>\n",
       "      <td>7</td>\n",
       "      <td>Typ</td>\n",
       "      <td>1</td>\n",
       "      <td>Detchd</td>\n",
       "      <td>1998.0</td>\n",
       "      <td>Unf</td>\n",
       "      <td>3.0</td>\n",
       "      <td>642.0</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>272</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>NoRidge</td>\n",
       "      <td>Norm</td>\n",
       "      <td>Norm</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>2Story</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>Gable</td>\n",
       "      <td>CompShg</td>\n",
       "      <td>VinylSd</td>\n",
       "      <td>VinylSd</td>\n",
       "      <td>350.0</td>\n",
       "      <td>Gd</td>\n",
       "      <td>TA</td>\n",
       "      <td>PConc</td>\n",
       "      <td>Gd</td>\n",
       "      <td>TA</td>\n",
       "      <td>Av</td>\n",
       "      <td>GLQ</td>\n",
       "      <td>655.0</td>\n",
       "      <td>Unf</td>\n",
       "      <td>0.0</td>\n",
       "      <td>490.0</td>\n",
       "      <td>1145.0</td>\n",
       "      <td>GasA</td>\n",
       "      <td>Ex</td>\n",
       "      <td>Y</td>\n",
       "      <td>SBrkr</td>\n",
       "      <td>1145</td>\n",
       "      <td>1053</td>\n",
       "      <td>0</td>\n",
       "      <td>2198</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Gd</td>\n",
       "      <td>9</td>\n",
       "      <td>Typ</td>\n",
       "      <td>1</td>\n",
       "      <td>Attchd</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>RFn</td>\n",
       "      <td>3.0</td>\n",
       "      <td>836.0</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>192</td>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1454</th>\n",
       "      <td>160</td>\n",
       "      <td>RM</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1936</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>MeadowV</td>\n",
       "      <td>Norm</td>\n",
       "      <td>Norm</td>\n",
       "      <td>Twnhs</td>\n",
       "      <td>2Story</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>1970</td>\n",
       "      <td>1970</td>\n",
       "      <td>Gable</td>\n",
       "      <td>CompShg</td>\n",
       "      <td>CemntBd</td>\n",
       "      <td>CmentBd</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>CBlock</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>No</td>\n",
       "      <td>Unf</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Unf</td>\n",
       "      <td>0.0</td>\n",
       "      <td>546.0</td>\n",
       "      <td>546.0</td>\n",
       "      <td>GasA</td>\n",
       "      <td>Gd</td>\n",
       "      <td>Y</td>\n",
       "      <td>SBrkr</td>\n",
       "      <td>546</td>\n",
       "      <td>546</td>\n",
       "      <td>0</td>\n",
       "      <td>1092</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>TA</td>\n",
       "      <td>5</td>\n",
       "      <td>Typ</td>\n",
       "      <td>0</td>\n",
       "      <td>Attchd</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>Unf</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>160</td>\n",
       "      <td>RM</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1894</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>MeadowV</td>\n",
       "      <td>Norm</td>\n",
       "      <td>Norm</td>\n",
       "      <td>TwnhsE</td>\n",
       "      <td>2Story</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1970</td>\n",
       "      <td>1970</td>\n",
       "      <td>Gable</td>\n",
       "      <td>CompShg</td>\n",
       "      <td>CemntBd</td>\n",
       "      <td>CmentBd</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>CBlock</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>No</td>\n",
       "      <td>Rec</td>\n",
       "      <td>252.0</td>\n",
       "      <td>Unf</td>\n",
       "      <td>0.0</td>\n",
       "      <td>294.0</td>\n",
       "      <td>546.0</td>\n",
       "      <td>GasA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>SBrkr</td>\n",
       "      <td>546</td>\n",
       "      <td>546</td>\n",
       "      <td>0</td>\n",
       "      <td>1092</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>TA</td>\n",
       "      <td>6</td>\n",
       "      <td>Typ</td>\n",
       "      <td>0</td>\n",
       "      <td>CarPort</td>\n",
       "      <td>1970.0</td>\n",
       "      <td>Unf</td>\n",
       "      <td>1.0</td>\n",
       "      <td>286.0</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>160.0</td>\n",
       "      <td>20000</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>Mitchel</td>\n",
       "      <td>Norm</td>\n",
       "      <td>Norm</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>1Story</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>1960</td>\n",
       "      <td>1996</td>\n",
       "      <td>Gable</td>\n",
       "      <td>CompShg</td>\n",
       "      <td>VinylSd</td>\n",
       "      <td>VinylSd</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>CBlock</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>No</td>\n",
       "      <td>ALQ</td>\n",
       "      <td>1224.0</td>\n",
       "      <td>Unf</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1224.0</td>\n",
       "      <td>GasA</td>\n",
       "      <td>Ex</td>\n",
       "      <td>Y</td>\n",
       "      <td>SBrkr</td>\n",
       "      <td>1224</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1224</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>TA</td>\n",
       "      <td>7</td>\n",
       "      <td>Typ</td>\n",
       "      <td>1</td>\n",
       "      <td>Detchd</td>\n",
       "      <td>1960.0</td>\n",
       "      <td>Unf</td>\n",
       "      <td>2.0</td>\n",
       "      <td>576.0</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>474</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>85</td>\n",
       "      <td>RL</td>\n",
       "      <td>62.0</td>\n",
       "      <td>10441</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>Mitchel</td>\n",
       "      <td>Norm</td>\n",
       "      <td>Norm</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>SFoyer</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1992</td>\n",
       "      <td>1992</td>\n",
       "      <td>Gable</td>\n",
       "      <td>CompShg</td>\n",
       "      <td>HdBoard</td>\n",
       "      <td>Wd Shng</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>PConc</td>\n",
       "      <td>Gd</td>\n",
       "      <td>TA</td>\n",
       "      <td>Av</td>\n",
       "      <td>GLQ</td>\n",
       "      <td>337.0</td>\n",
       "      <td>Unf</td>\n",
       "      <td>0.0</td>\n",
       "      <td>575.0</td>\n",
       "      <td>912.0</td>\n",
       "      <td>GasA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>SBrkr</td>\n",
       "      <td>970</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>970</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>TA</td>\n",
       "      <td>6</td>\n",
       "      <td>Typ</td>\n",
       "      <td>0</td>\n",
       "      <td>Attchd</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>Unf</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>80</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>700</td>\n",
       "      <td>7</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>74.0</td>\n",
       "      <td>9627</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Mod</td>\n",
       "      <td>Mitchel</td>\n",
       "      <td>Norm</td>\n",
       "      <td>Norm</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>2Story</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1993</td>\n",
       "      <td>1994</td>\n",
       "      <td>Gable</td>\n",
       "      <td>CompShg</td>\n",
       "      <td>HdBoard</td>\n",
       "      <td>HdBoard</td>\n",
       "      <td>94.0</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>PConc</td>\n",
       "      <td>Gd</td>\n",
       "      <td>TA</td>\n",
       "      <td>Av</td>\n",
       "      <td>LwQ</td>\n",
       "      <td>758.0</td>\n",
       "      <td>Unf</td>\n",
       "      <td>0.0</td>\n",
       "      <td>238.0</td>\n",
       "      <td>996.0</td>\n",
       "      <td>GasA</td>\n",
       "      <td>Ex</td>\n",
       "      <td>Y</td>\n",
       "      <td>SBrkr</td>\n",
       "      <td>996</td>\n",
       "      <td>1004</td>\n",
       "      <td>0</td>\n",
       "      <td>2000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>TA</td>\n",
       "      <td>9</td>\n",
       "      <td>Typ</td>\n",
       "      <td>1</td>\n",
       "      <td>Attchd</td>\n",
       "      <td>1993.0</td>\n",
       "      <td>Fin</td>\n",
       "      <td>3.0</td>\n",
       "      <td>650.0</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>190</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2919 rows  74 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      MSSubClass MSZoning  LotFrontage  LotArea Street LotShape LandContour  \\\n",
       "0             60       RL         65.0     8450   Pave      Reg         Lvl   \n",
       "1             20       RL         80.0     9600   Pave      Reg         Lvl   \n",
       "2             60       RL         68.0    11250   Pave      IR1         Lvl   \n",
       "3             70       RL         60.0     9550   Pave      IR1         Lvl   \n",
       "4             60       RL         84.0    14260   Pave      IR1         Lvl   \n",
       "...          ...      ...          ...      ...    ...      ...         ...   \n",
       "1454         160       RM         21.0     1936   Pave      Reg         Lvl   \n",
       "1455         160       RM         21.0     1894   Pave      Reg         Lvl   \n",
       "1456          20       RL        160.0    20000   Pave      Reg         Lvl   \n",
       "1457          85       RL         62.0    10441   Pave      Reg         Lvl   \n",
       "1458          60       RL         74.0     9627   Pave      Reg         Lvl   \n",
       "\n",
       "     Utilities LotConfig LandSlope Neighborhood Condition1 Condition2  \\\n",
       "0       AllPub    Inside       Gtl      CollgCr       Norm       Norm   \n",
       "1       AllPub       FR2       Gtl      Veenker      Feedr       Norm   \n",
       "2       AllPub    Inside       Gtl      CollgCr       Norm       Norm   \n",
       "3       AllPub    Corner       Gtl      Crawfor       Norm       Norm   \n",
       "4       AllPub       FR2       Gtl      NoRidge       Norm       Norm   \n",
       "...        ...       ...       ...          ...        ...        ...   \n",
       "1454    AllPub    Inside       Gtl      MeadowV       Norm       Norm   \n",
       "1455    AllPub    Inside       Gtl      MeadowV       Norm       Norm   \n",
       "1456    AllPub    Inside       Gtl      Mitchel       Norm       Norm   \n",
       "1457    AllPub    Inside       Gtl      Mitchel       Norm       Norm   \n",
       "1458    AllPub    Inside       Mod      Mitchel       Norm       Norm   \n",
       "\n",
       "     BldgType HouseStyle  OverallQual  OverallCond  YearBuilt  YearRemodAdd  \\\n",
       "0        1Fam     2Story            7            5       2003          2003   \n",
       "1        1Fam     1Story            6            8       1976          1976   \n",
       "2        1Fam     2Story            7            5       2001          2002   \n",
       "3        1Fam     2Story            7            5       1915          1970   \n",
       "4        1Fam     2Story            8            5       2000          2000   \n",
       "...       ...        ...          ...          ...        ...           ...   \n",
       "1454    Twnhs     2Story            4            7       1970          1970   \n",
       "1455   TwnhsE     2Story            4            5       1970          1970   \n",
       "1456     1Fam     1Story            5            7       1960          1996   \n",
       "1457     1Fam     SFoyer            5            5       1992          1992   \n",
       "1458     1Fam     2Story            7            5       1993          1994   \n",
       "\n",
       "     RoofStyle RoofMatl Exterior1st Exterior2nd  MasVnrArea ExterQual  \\\n",
       "0        Gable  CompShg     VinylSd     VinylSd       196.0        Gd   \n",
       "1        Gable  CompShg     MetalSd     MetalSd         0.0        TA   \n",
       "2        Gable  CompShg     VinylSd     VinylSd       162.0        Gd   \n",
       "3        Gable  CompShg     Wd Sdng     Wd Shng         0.0        TA   \n",
       "4        Gable  CompShg     VinylSd     VinylSd       350.0        Gd   \n",
       "...        ...      ...         ...         ...         ...       ...   \n",
       "1454     Gable  CompShg     CemntBd     CmentBd         0.0        TA   \n",
       "1455     Gable  CompShg     CemntBd     CmentBd         0.0        TA   \n",
       "1456     Gable  CompShg     VinylSd     VinylSd         0.0        TA   \n",
       "1457     Gable  CompShg     HdBoard     Wd Shng         0.0        TA   \n",
       "1458     Gable  CompShg     HdBoard     HdBoard        94.0        TA   \n",
       "\n",
       "     ExterCond Foundation BsmtQual BsmtCond BsmtExposure BsmtFinType1  \\\n",
       "0           TA      PConc       Gd       TA           No          GLQ   \n",
       "1           TA     CBlock       Gd       TA           Gd          ALQ   \n",
       "2           TA      PConc       Gd       TA           Mn          GLQ   \n",
       "3           TA     BrkTil       TA       Gd           No          ALQ   \n",
       "4           TA      PConc       Gd       TA           Av          GLQ   \n",
       "...        ...        ...      ...      ...          ...          ...   \n",
       "1454        TA     CBlock       TA       TA           No          Unf   \n",
       "1455        TA     CBlock       TA       TA           No          Rec   \n",
       "1456        TA     CBlock       TA       TA           No          ALQ   \n",
       "1457        TA      PConc       Gd       TA           Av          GLQ   \n",
       "1458        TA      PConc       Gd       TA           Av          LwQ   \n",
       "\n",
       "      BsmtFinSF1 BsmtFinType2  BsmtFinSF2  BsmtUnfSF  TotalBsmtSF Heating  \\\n",
       "0          706.0          Unf         0.0      150.0        856.0    GasA   \n",
       "1          978.0          Unf         0.0      284.0       1262.0    GasA   \n",
       "2          486.0          Unf         0.0      434.0        920.0    GasA   \n",
       "3          216.0          Unf         0.0      540.0        756.0    GasA   \n",
       "4          655.0          Unf         0.0      490.0       1145.0    GasA   \n",
       "...          ...          ...         ...        ...          ...     ...   \n",
       "1454         0.0          Unf         0.0      546.0        546.0    GasA   \n",
       "1455       252.0          Unf         0.0      294.0        546.0    GasA   \n",
       "1456      1224.0          Unf         0.0        0.0       1224.0    GasA   \n",
       "1457       337.0          Unf         0.0      575.0        912.0    GasA   \n",
       "1458       758.0          Unf         0.0      238.0        996.0    GasA   \n",
       "\n",
       "     HeatingQC CentralAir Electrical  1stFlrSF  2ndFlrSF  LowQualFinSF  \\\n",
       "0           Ex          Y      SBrkr       856       854             0   \n",
       "1           Ex          Y      SBrkr      1262         0             0   \n",
       "2           Ex          Y      SBrkr       920       866             0   \n",
       "3           Gd          Y      SBrkr       961       756             0   \n",
       "4           Ex          Y      SBrkr      1145      1053             0   \n",
       "...        ...        ...        ...       ...       ...           ...   \n",
       "1454        Gd          Y      SBrkr       546       546             0   \n",
       "1455        TA          Y      SBrkr       546       546             0   \n",
       "1456        Ex          Y      SBrkr      1224         0             0   \n",
       "1457        TA          Y      SBrkr       970         0             0   \n",
       "1458        Ex          Y      SBrkr       996      1004             0   \n",
       "\n",
       "      GrLivArea  BsmtFullBath  BsmtHalfBath  FullBath  HalfBath  BedroomAbvGr  \\\n",
       "0          1710           1.0           0.0         2         1             3   \n",
       "1          1262           0.0           1.0         2         0             3   \n",
       "2          1786           1.0           0.0         2         1             3   \n",
       "3          1717           1.0           0.0         1         0             3   \n",
       "4          2198           1.0           0.0         2         1             4   \n",
       "...         ...           ...           ...       ...       ...           ...   \n",
       "1454       1092           0.0           0.0         1         1             3   \n",
       "1455       1092           0.0           0.0         1         1             3   \n",
       "1456       1224           1.0           0.0         1         0             4   \n",
       "1457        970           0.0           1.0         1         0             3   \n",
       "1458       2000           0.0           0.0         2         1             3   \n",
       "\n",
       "      KitchenAbvGr KitchenQual  TotRmsAbvGrd Functional  Fireplaces  \\\n",
       "0                1          Gd             8        Typ           0   \n",
       "1                1          TA             6        Typ           1   \n",
       "2                1          Gd             6        Typ           1   \n",
       "3                1          Gd             7        Typ           1   \n",
       "4                1          Gd             9        Typ           1   \n",
       "...            ...         ...           ...        ...         ...   \n",
       "1454             1          TA             5        Typ           0   \n",
       "1455             1          TA             6        Typ           0   \n",
       "1456             1          TA             7        Typ           1   \n",
       "1457             1          TA             6        Typ           0   \n",
       "1458             1          TA             9        Typ           1   \n",
       "\n",
       "     GarageType  GarageYrBlt GarageFinish  GarageCars  GarageArea GarageQual  \\\n",
       "0        Attchd       2003.0          RFn         2.0       548.0         TA   \n",
       "1        Attchd       1976.0          RFn         2.0       460.0         TA   \n",
       "2        Attchd       2001.0          RFn         2.0       608.0         TA   \n",
       "3        Detchd       1998.0          Unf         3.0       642.0         TA   \n",
       "4        Attchd       2000.0          RFn         3.0       836.0         TA   \n",
       "...         ...          ...          ...         ...         ...        ...   \n",
       "1454     Attchd       2005.0          Unf         0.0         0.0         TA   \n",
       "1455    CarPort       1970.0          Unf         1.0       286.0         TA   \n",
       "1456     Detchd       1960.0          Unf         2.0       576.0         TA   \n",
       "1457     Attchd       2005.0          Unf         0.0         0.0         TA   \n",
       "1458     Attchd       1993.0          Fin         3.0       650.0         TA   \n",
       "\n",
       "     GarageCond PavedDrive  WoodDeckSF  OpenPorchSF  EnclosedPorch  3SsnPorch  \\\n",
       "0            TA          Y           0           61              0          0   \n",
       "1            TA          Y         298            0              0          0   \n",
       "2            TA          Y           0           42              0          0   \n",
       "3            TA          Y           0           35            272          0   \n",
       "4            TA          Y         192           84              0          0   \n",
       "...         ...        ...         ...          ...            ...        ...   \n",
       "1454         TA          Y           0            0              0          0   \n",
       "1455         TA          Y           0           24              0          0   \n",
       "1456         TA          Y         474            0              0          0   \n",
       "1457         TA          Y          80           32              0          0   \n",
       "1458         TA          Y         190           48              0          0   \n",
       "\n",
       "      ScreenPorch  PoolArea  MiscVal  MoSold  YrSold SaleType SaleCondition  \\\n",
       "0               0         0        0       2    2008       WD        Normal   \n",
       "1               0         0        0       5    2007       WD        Normal   \n",
       "2               0         0        0       9    2008       WD        Normal   \n",
       "3               0         0        0       2    2006       WD       Abnorml   \n",
       "4               0         0        0      12    2008       WD        Normal   \n",
       "...           ...       ...      ...     ...     ...      ...           ...   \n",
       "1454            0         0        0       6    2006       WD        Normal   \n",
       "1455            0         0        0       4    2006       WD       Abnorml   \n",
       "1456            0         0        0       9    2006       WD       Abnorml   \n",
       "1457            0         0      700       7    2006       WD        Normal   \n",
       "1458            0         0        0      11    2006       WD        Normal   \n",
       "\n",
       "      SalePrice  \n",
       "0      208500.0  \n",
       "1      181500.0  \n",
       "2      223500.0  \n",
       "3      140000.0  \n",
       "4      250000.0  \n",
       "...         ...  \n",
       "1454        NaN  \n",
       "1455        NaN  \n",
       "1456        NaN  \n",
       "1457        NaN  \n",
       "1458        NaN  \n",
       "\n",
       "[2919 rows x 74 columns]"
      ]
     },
     "execution_count": 617,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df=pd.concat([df,test_df],axis=0)\n",
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MSSubClass          0\n",
       "MSZoning            0\n",
       "LotFrontage         0\n",
       "LotArea             0\n",
       "Street              0\n",
       "                 ... \n",
       "MoSold              0\n",
       "YrSold              0\n",
       "SaleType            0\n",
       "SaleCondition       0\n",
       "SalePrice        1459\n",
       "Length: 74, dtype: int64"
      ]
     },
     "execution_count": 618,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "metadata": {},
   "outputs": [],
   "source": [
    "# handale categorical features\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['MSZoning', 'Street', 'LotShape', 'LandContour', 'Utilities',\n",
       "       'LotConfig', 'LandSlope', 'Neighborhood', 'Condition1', 'Condition2',\n",
       "       'BldgType', 'HouseStyle', 'RoofStyle', 'RoofMatl', 'Exterior1st',\n",
       "       'Exterior2nd', 'ExterQual', 'ExterCond', 'Foundation', 'BsmtQual',\n",
       "       'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2', 'Heating',\n",
       "       'HeatingQC', 'CentralAir', 'Electrical', 'KitchenQual', 'Functional',\n",
       "       'GarageType', 'GarageFinish', 'GarageQual', 'GarageCond', 'PavedDrive',\n",
       "       'SaleType', 'SaleCondition'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 619,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_columns=final_df.select_dtypes(include=['object']).columns\n",
    "categorical_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 620,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(categorical_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "metadata": {},
   "outputs": [],
   "source": [
    "def category_onehot_multcols(multcolumns):\n",
    "    df_final=final_df\n",
    "    i=0\n",
    "    for fields in multcolumns:\n",
    "        \n",
    "        \n",
    "        df1=pd.get_dummies(final_df[fields],drop_first=True)\n",
    "        \n",
    "        final_df.drop([fields],axis=1,inplace=True)\n",
    "        if i==0:\n",
    "            df_final=df1.copy()\n",
    "        else:\n",
    "            \n",
    "            df_final=pd.concat([df_final,df1],axis=1)\n",
    "        i=i+1\n",
    "       \n",
    "        \n",
    "    df_final=pd.concat([final_df,df_final],axis=1)\n",
    "        \n",
    "    return df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2919, 230)"
      ]
     },
     "execution_count": 622,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df=category_onehot_multcols(categorical_columns)\n",
    "final_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2919, 176)"
      ]
     },
     "execution_count": 623,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df =final_df.loc[:,~final_df.columns.duplicated()]\n",
    "final_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Train=final_df.iloc[:1460,:]\n",
    "df_Test=final_df.iloc[1460:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 625,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1459, 176)"
      ]
     },
     "execution_count": 625,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 633,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SDS\\AppData\\Local\\Temp\\ipykernel_19004\\3441760400.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_Test.drop(columns=['SalePrice'],inplace=True)\n"
     ]
    }
   ],
   "source": [
    "df_Test.drop(columns=['SalePrice'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 637,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1459, 175)"
      ]
     },
     "execution_count": 637,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 626,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1460, 176)"
      ]
     },
     "execution_count": 626,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>BsmtUnfSF</th>\n",
       "      <th>TotalBsmtSF</th>\n",
       "      <th>1stFlrSF</th>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <th>LowQualFinSF</th>\n",
       "      <th>GrLivArea</th>\n",
       "      <th>BsmtFullBath</th>\n",
       "      <th>BsmtHalfBath</th>\n",
       "      <th>FullBath</th>\n",
       "      <th>HalfBath</th>\n",
       "      <th>BedroomAbvGr</th>\n",
       "      <th>KitchenAbvGr</th>\n",
       "      <th>TotRmsAbvGrd</th>\n",
       "      <th>Fireplaces</th>\n",
       "      <th>GarageYrBlt</th>\n",
       "      <th>GarageCars</th>\n",
       "      <th>GarageArea</th>\n",
       "      <th>WoodDeckSF</th>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SalePrice</th>\n",
       "      <th>FV</th>\n",
       "      <th>RH</th>\n",
       "      <th>RL</th>\n",
       "      <th>RM</th>\n",
       "      <th>Pave</th>\n",
       "      <th>IR2</th>\n",
       "      <th>IR3</th>\n",
       "      <th>Reg</th>\n",
       "      <th>HLS</th>\n",
       "      <th>Low</th>\n",
       "      <th>Lvl</th>\n",
       "      <th>NoSeWa</th>\n",
       "      <th>CulDSac</th>\n",
       "      <th>FR2</th>\n",
       "      <th>FR3</th>\n",
       "      <th>Inside</th>\n",
       "      <th>Mod</th>\n",
       "      <th>Sev</th>\n",
       "      <th>Blueste</th>\n",
       "      <th>BrDale</th>\n",
       "      <th>BrkSide</th>\n",
       "      <th>ClearCr</th>\n",
       "      <th>CollgCr</th>\n",
       "      <th>Crawfor</th>\n",
       "      <th>Edwards</th>\n",
       "      <th>Gilbert</th>\n",
       "      <th>IDOTRR</th>\n",
       "      <th>MeadowV</th>\n",
       "      <th>Mitchel</th>\n",
       "      <th>NAmes</th>\n",
       "      <th>NPkVill</th>\n",
       "      <th>NWAmes</th>\n",
       "      <th>NoRidge</th>\n",
       "      <th>NridgHt</th>\n",
       "      <th>OldTown</th>\n",
       "      <th>SWISU</th>\n",
       "      <th>Sawyer</th>\n",
       "      <th>SawyerW</th>\n",
       "      <th>Somerst</th>\n",
       "      <th>StoneBr</th>\n",
       "      <th>Timber</th>\n",
       "      <th>Veenker</th>\n",
       "      <th>Feedr</th>\n",
       "      <th>Norm</th>\n",
       "      <th>PosA</th>\n",
       "      <th>PosN</th>\n",
       "      <th>RRAe</th>\n",
       "      <th>RRAn</th>\n",
       "      <th>RRNe</th>\n",
       "      <th>RRNn</th>\n",
       "      <th>2fmCon</th>\n",
       "      <th>Duplex</th>\n",
       "      <th>Twnhs</th>\n",
       "      <th>TwnhsE</th>\n",
       "      <th>1.5Unf</th>\n",
       "      <th>1Story</th>\n",
       "      <th>2.5Fin</th>\n",
       "      <th>2.5Unf</th>\n",
       "      <th>2Story</th>\n",
       "      <th>SFoyer</th>\n",
       "      <th>SLvl</th>\n",
       "      <th>Gable</th>\n",
       "      <th>Gambrel</th>\n",
       "      <th>Hip</th>\n",
       "      <th>Mansard</th>\n",
       "      <th>Shed</th>\n",
       "      <th>CompShg</th>\n",
       "      <th>Membran</th>\n",
       "      <th>Metal</th>\n",
       "      <th>Roll</th>\n",
       "      <th>Tar&amp;Grv</th>\n",
       "      <th>WdShake</th>\n",
       "      <th>WdShngl</th>\n",
       "      <th>AsphShn</th>\n",
       "      <th>BrkComm</th>\n",
       "      <th>BrkFace</th>\n",
       "      <th>CBlock</th>\n",
       "      <th>CemntBd</th>\n",
       "      <th>HdBoard</th>\n",
       "      <th>ImStucc</th>\n",
       "      <th>MetalSd</th>\n",
       "      <th>Plywood</th>\n",
       "      <th>Stone</th>\n",
       "      <th>Stucco</th>\n",
       "      <th>VinylSd</th>\n",
       "      <th>Wd Sdng</th>\n",
       "      <th>WdShing</th>\n",
       "      <th>Brk Cmn</th>\n",
       "      <th>CmentBd</th>\n",
       "      <th>Other</th>\n",
       "      <th>Wd Shng</th>\n",
       "      <th>Fa</th>\n",
       "      <th>Gd</th>\n",
       "      <th>TA</th>\n",
       "      <th>Po</th>\n",
       "      <th>PConc</th>\n",
       "      <th>Slab</th>\n",
       "      <th>Wood</th>\n",
       "      <th>Mn</th>\n",
       "      <th>No</th>\n",
       "      <th>BLQ</th>\n",
       "      <th>GLQ</th>\n",
       "      <th>LwQ</th>\n",
       "      <th>Rec</th>\n",
       "      <th>Unf</th>\n",
       "      <th>GasA</th>\n",
       "      <th>GasW</th>\n",
       "      <th>Grav</th>\n",
       "      <th>OthW</th>\n",
       "      <th>Wall</th>\n",
       "      <th>Y</th>\n",
       "      <th>FuseF</th>\n",
       "      <th>FuseP</th>\n",
       "      <th>Mix</th>\n",
       "      <th>SBrkr</th>\n",
       "      <th>Maj2</th>\n",
       "      <th>Min1</th>\n",
       "      <th>Min2</th>\n",
       "      <th>Typ</th>\n",
       "      <th>Attchd</th>\n",
       "      <th>Basment</th>\n",
       "      <th>BuiltIn</th>\n",
       "      <th>CarPort</th>\n",
       "      <th>Detchd</th>\n",
       "      <th>RFn</th>\n",
       "      <th>P</th>\n",
       "      <th>CWD</th>\n",
       "      <th>Con</th>\n",
       "      <th>ConLD</th>\n",
       "      <th>ConLI</th>\n",
       "      <th>ConLw</th>\n",
       "      <th>New</th>\n",
       "      <th>Oth</th>\n",
       "      <th>WD</th>\n",
       "      <th>AdjLand</th>\n",
       "      <th>Alloca</th>\n",
       "      <th>Family</th>\n",
       "      <th>Normal</th>\n",
       "      <th>Partial</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2003</td>\n",
       "      <td>2003</td>\n",
       "      <td>196.0</td>\n",
       "      <td>706.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>856.0</td>\n",
       "      <td>856</td>\n",
       "      <td>854</td>\n",
       "      <td>0</td>\n",
       "      <td>1710</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>548.0</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>208500.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>1976</td>\n",
       "      <td>1976</td>\n",
       "      <td>0.0</td>\n",
       "      <td>978.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>284.0</td>\n",
       "      <td>1262.0</td>\n",
       "      <td>1262</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1262</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1976.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>460.0</td>\n",
       "      <td>298</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>181500.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2001</td>\n",
       "      <td>2002</td>\n",
       "      <td>162.0</td>\n",
       "      <td>486.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>434.0</td>\n",
       "      <td>920.0</td>\n",
       "      <td>920</td>\n",
       "      <td>866</td>\n",
       "      <td>0</td>\n",
       "      <td>1786</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>608.0</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>223500.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1915</td>\n",
       "      <td>1970</td>\n",
       "      <td>0.0</td>\n",
       "      <td>216.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>540.0</td>\n",
       "      <td>756.0</td>\n",
       "      <td>961</td>\n",
       "      <td>756</td>\n",
       "      <td>0</td>\n",
       "      <td>1717</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1998.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>642.0</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>272</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>140000.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>350.0</td>\n",
       "      <td>655.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>490.0</td>\n",
       "      <td>1145.0</td>\n",
       "      <td>1145</td>\n",
       "      <td>1053</td>\n",
       "      <td>0</td>\n",
       "      <td>2198</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>836.0</td>\n",
       "      <td>192</td>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>250000.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MSSubClass  LotFrontage  LotArea  OverallQual  OverallCond  YearBuilt  \\\n",
       "0          60         65.0     8450            7            5       2003   \n",
       "1          20         80.0     9600            6            8       1976   \n",
       "2          60         68.0    11250            7            5       2001   \n",
       "3          70         60.0     9550            7            5       1915   \n",
       "4          60         84.0    14260            8            5       2000   \n",
       "\n",
       "   YearRemodAdd  MasVnrArea  BsmtFinSF1  BsmtFinSF2  BsmtUnfSF  TotalBsmtSF  \\\n",
       "0          2003       196.0       706.0         0.0      150.0        856.0   \n",
       "1          1976         0.0       978.0         0.0      284.0       1262.0   \n",
       "2          2002       162.0       486.0         0.0      434.0        920.0   \n",
       "3          1970         0.0       216.0         0.0      540.0        756.0   \n",
       "4          2000       350.0       655.0         0.0      490.0       1145.0   \n",
       "\n",
       "   1stFlrSF  2ndFlrSF  LowQualFinSF  GrLivArea  BsmtFullBath  BsmtHalfBath  \\\n",
       "0       856       854             0       1710           1.0           0.0   \n",
       "1      1262         0             0       1262           0.0           1.0   \n",
       "2       920       866             0       1786           1.0           0.0   \n",
       "3       961       756             0       1717           1.0           0.0   \n",
       "4      1145      1053             0       2198           1.0           0.0   \n",
       "\n",
       "   FullBath  HalfBath  BedroomAbvGr  KitchenAbvGr  TotRmsAbvGrd  Fireplaces  \\\n",
       "0         2         1             3             1             8           0   \n",
       "1         2         0             3             1             6           1   \n",
       "2         2         1             3             1             6           1   \n",
       "3         1         0             3             1             7           1   \n",
       "4         2         1             4             1             9           1   \n",
       "\n",
       "   GarageYrBlt  GarageCars  GarageArea  WoodDeckSF  OpenPorchSF  \\\n",
       "0       2003.0         2.0       548.0           0           61   \n",
       "1       1976.0         2.0       460.0         298            0   \n",
       "2       2001.0         2.0       608.0           0           42   \n",
       "3       1998.0         3.0       642.0           0           35   \n",
       "4       2000.0         3.0       836.0         192           84   \n",
       "\n",
       "   EnclosedPorch  3SsnPorch  ScreenPorch  PoolArea  MiscVal  MoSold  YrSold  \\\n",
       "0              0          0            0         0        0       2    2008   \n",
       "1              0          0            0         0        0       5    2007   \n",
       "2              0          0            0         0        0       9    2008   \n",
       "3            272          0            0         0        0       2    2006   \n",
       "4              0          0            0         0        0      12    2008   \n",
       "\n",
       "   SalePrice     FV     RH    RL     RM  Pave    IR2    IR3    Reg    HLS  \\\n",
       "0   208500.0  False  False  True  False  True  False  False   True  False   \n",
       "1   181500.0  False  False  True  False  True  False  False   True  False   \n",
       "2   223500.0  False  False  True  False  True  False  False  False  False   \n",
       "3   140000.0  False  False  True  False  True  False  False  False  False   \n",
       "4   250000.0  False  False  True  False  True  False  False  False  False   \n",
       "\n",
       "     Low   Lvl  NoSeWa  CulDSac    FR2    FR3  Inside    Mod    Sev  Blueste  \\\n",
       "0  False  True   False    False  False  False    True  False  False    False   \n",
       "1  False  True   False    False   True  False   False  False  False    False   \n",
       "2  False  True   False    False  False  False    True  False  False    False   \n",
       "3  False  True   False    False  False  False   False  False  False    False   \n",
       "4  False  True   False    False   True  False   False  False  False    False   \n",
       "\n",
       "   BrDale  BrkSide  ClearCr  CollgCr  Crawfor  Edwards  Gilbert  IDOTRR  \\\n",
       "0   False    False    False     True    False    False    False   False   \n",
       "1   False    False    False    False    False    False    False   False   \n",
       "2   False    False    False     True    False    False    False   False   \n",
       "3   False    False    False    False     True    False    False   False   \n",
       "4   False    False    False    False    False    False    False   False   \n",
       "\n",
       "   MeadowV  Mitchel  NAmes  NPkVill  NWAmes  NoRidge  NridgHt  OldTown  SWISU  \\\n",
       "0    False    False  False    False   False    False    False    False  False   \n",
       "1    False    False  False    False   False    False    False    False  False   \n",
       "2    False    False  False    False   False    False    False    False  False   \n",
       "3    False    False  False    False   False    False    False    False  False   \n",
       "4    False    False  False    False   False     True    False    False  False   \n",
       "\n",
       "   Sawyer  SawyerW  Somerst  StoneBr  Timber  Veenker  Feedr   Norm   PosA  \\\n",
       "0   False    False    False    False   False    False  False   True  False   \n",
       "1   False    False    False    False   False     True   True  False  False   \n",
       "2   False    False    False    False   False    False  False   True  False   \n",
       "3   False    False    False    False   False    False  False   True  False   \n",
       "4   False    False    False    False   False    False  False   True  False   \n",
       "\n",
       "    PosN   RRAe   RRAn   RRNe   RRNn  2fmCon  Duplex  Twnhs  TwnhsE  1.5Unf  \\\n",
       "0  False  False  False  False  False   False   False  False   False   False   \n",
       "1  False  False  False  False  False   False   False  False   False   False   \n",
       "2  False  False  False  False  False   False   False  False   False   False   \n",
       "3  False  False  False  False  False   False   False  False   False   False   \n",
       "4  False  False  False  False  False   False   False  False   False   False   \n",
       "\n",
       "   1Story  2.5Fin  2.5Unf  2Story  SFoyer   SLvl  Gable  Gambrel    Hip  \\\n",
       "0   False   False   False    True   False  False   True    False  False   \n",
       "1    True   False   False   False   False  False   True    False  False   \n",
       "2   False   False   False    True   False  False   True    False  False   \n",
       "3   False   False   False    True   False  False   True    False  False   \n",
       "4   False   False   False    True   False  False   True    False  False   \n",
       "\n",
       "   Mansard   Shed  CompShg  Membran  Metal   Roll  Tar&Grv  WdShake  WdShngl  \\\n",
       "0    False  False     True    False  False  False    False    False    False   \n",
       "1    False  False     True    False  False  False    False    False    False   \n",
       "2    False  False     True    False  False  False    False    False    False   \n",
       "3    False  False     True    False  False  False    False    False    False   \n",
       "4    False  False     True    False  False  False    False    False    False   \n",
       "\n",
       "   AsphShn  BrkComm  BrkFace  CBlock  CemntBd  HdBoard  ImStucc  MetalSd  \\\n",
       "0    False    False    False   False    False    False    False    False   \n",
       "1    False    False    False   False    False    False    False     True   \n",
       "2    False    False    False   False    False    False    False    False   \n",
       "3    False    False    False   False    False    False    False    False   \n",
       "4    False    False    False   False    False    False    False    False   \n",
       "\n",
       "   Plywood  Stone  Stucco  VinylSd  Wd Sdng  WdShing  Brk Cmn  CmentBd  Other  \\\n",
       "0    False  False   False     True    False    False    False    False  False   \n",
       "1    False  False   False    False    False    False    False    False  False   \n",
       "2    False  False   False     True    False    False    False    False  False   \n",
       "3    False  False   False    False     True    False    False    False  False   \n",
       "4    False  False   False     True    False    False    False    False  False   \n",
       "\n",
       "   Wd Shng     Fa     Gd     TA     Po  PConc   Slab   Wood     Mn     No  \\\n",
       "0    False  False   True  False  False   True  False  False  False   True   \n",
       "1    False  False  False   True  False  False  False  False  False  False   \n",
       "2    False  False   True  False  False   True  False  False   True  False   \n",
       "3     True  False  False   True  False  False  False  False  False   True   \n",
       "4    False  False   True  False  False   True  False  False  False  False   \n",
       "\n",
       "     BLQ    GLQ    LwQ    Rec    Unf  GasA   GasW   Grav   OthW   Wall     Y  \\\n",
       "0  False   True  False  False  False  True  False  False  False  False  True   \n",
       "1  False  False  False  False  False  True  False  False  False  False  True   \n",
       "2  False   True  False  False  False  True  False  False  False  False  True   \n",
       "3  False  False  False  False  False  True  False  False  False  False  True   \n",
       "4  False   True  False  False  False  True  False  False  False  False  True   \n",
       "\n",
       "   FuseF  FuseP    Mix  SBrkr   Maj2   Min1   Min2   Typ  Attchd  Basment  \\\n",
       "0  False  False  False   True  False  False  False  True    True    False   \n",
       "1  False  False  False   True  False  False  False  True    True    False   \n",
       "2  False  False  False   True  False  False  False  True    True    False   \n",
       "3  False  False  False   True  False  False  False  True   False    False   \n",
       "4  False  False  False   True  False  False  False  True    True    False   \n",
       "\n",
       "   BuiltIn  CarPort  Detchd    RFn      P    CWD    Con  ConLD  ConLI  ConLw  \\\n",
       "0    False    False   False   True  False  False  False  False  False  False   \n",
       "1    False    False   False   True  False  False  False  False  False  False   \n",
       "2    False    False   False   True  False  False  False  False  False  False   \n",
       "3    False    False    True  False  False  False  False  False  False  False   \n",
       "4    False    False   False   True  False  False  False  False  False  False   \n",
       "\n",
       "     New    Oth    WD  AdjLand  Alloca  Family  Normal  Partial  \n",
       "0  False  False  True    False   False   False    True    False  \n",
       "1  False  False  True    False   False   False    True    False  \n",
       "2  False  False  True    False   False   False    True    False  \n",
       "3  False  False  True    False   False   False   False    False  \n",
       "4  False  False  True    False   False   False    True    False  "
      ]
     },
     "execution_count": 572,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 638,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=df_Train.drop(['SalePrice'],axis=1)\n",
    "y_train=df_Train['SalePrice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 639,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1460, 175)"
      ]
     },
     "execution_count": 639,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1,x2,y1,y2=train_test_split(x_train,y_train,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-41 {color: black;}#sk-container-id-41 pre{padding: 0;}#sk-container-id-41 div.sk-toggleable {background-color: white;}#sk-container-id-41 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-41 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-41 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-41 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-41 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-41 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-41 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-41 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-41 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-41 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-41 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-41 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-41 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-41 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-41 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-41 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-41 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-41 div.sk-item {position: relative;z-index: 1;}#sk-container-id-41 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-41 div.sk-item::before, #sk-container-id-41 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-41 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-41 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-41 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-41 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-41 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-41 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-41 div.sk-label-container {text-align: center;}#sk-container-id-41 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-41 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-41\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GradientBoostingRegressor(alpha=0.01, learning_rate=0.2, max_depth=5,\n",
       "                          n_estimators=200)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-43\" type=\"checkbox\" checked><label for=\"sk-estimator-id-43\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingRegressor</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingRegressor(alpha=0.01, learning_rate=0.2, max_depth=5,\n",
       "                          n_estimators=200)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.01, learning_rate=0.2, max_depth=5,\n",
       "                          n_estimators=200)"
      ]
     },
     "execution_count": 577,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbr=GradientBoostingRegressor(learning_rate=0.2,max_depth=5,n_estimators=200,alpha=0.01)\n",
    "gbr.fit(x1,y1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8958208102198756"
      ]
     },
     "execution_count": 578,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred1=gbr.predict(x2)\n",
    "r2_score(y2,y_pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 641,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbr=GradientBoostingRegressor(learning_rate=0.2,max_depth=3,n_estimators=200,alpha=0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 642,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-43 {color: black;}#sk-container-id-43 pre{padding: 0;}#sk-container-id-43 div.sk-toggleable {background-color: white;}#sk-container-id-43 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-43 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-43 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-43 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-43 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-43 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-43 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-43 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-43 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-43 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-43 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-43 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-43 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-43 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-43 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-43 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-43 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-43 div.sk-item {position: relative;z-index: 1;}#sk-container-id-43 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-43 div.sk-item::before, #sk-container-id-43 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-43 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-43 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-43 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-43 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-43 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-43 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-43 div.sk-label-container {text-align: center;}#sk-container-id-43 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-43 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-43\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GradientBoostingRegressor(alpha=0.01, learning_rate=0.2, n_estimators=200)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-45\" type=\"checkbox\" checked><label for=\"sk-estimator-id-45\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingRegressor</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingRegressor(alpha=0.01, learning_rate=0.2, n_estimators=200)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.01, learning_rate=0.2, n_estimators=200)"
      ]
     },
     "execution_count": 642,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbr.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "file_name='model_final.pkl'\n",
    "pickle.dump(gbr,open(file_name,'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 643,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=gbr.predict(df_Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 677,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=pd.DataFrame(ypred8)\n",
    "submisson=pd.read_csv(r'C:\\Users\\SDS\\Documents\\house price\\sample_submission.csv')\n",
    "dataset=pd.concat([submisson['Id'],pred],axis=1)\n",
    "dataset.columns=['Id','SalePrice']\n",
    "#dataset['SalePrice']=np.sqrt(dataset['SalePrice']**2)\n",
    "\n",
    "dataset.to_csv('model_9.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper parameter tunning \n",
    "dataset['SalePrice']=np.sqrt(dataset['SalePrice']**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'learning_rate': [0.05, 0.1, 0.2],\n",
    "    'max_depth': [3, 4, 5]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=GradientBoostingRegressor(),\n",
       "             param_grid={&#x27;learning_rate&#x27;: [0.05, 0.1, 0.2],\n",
       "                         &#x27;max_depth&#x27;: [3, 4, 5],\n",
       "                         &#x27;n_estimators&#x27;: [100, 200, 300]},\n",
       "             scoring=&#x27;neg_mean_squared_error&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=GradientBoostingRegressor(),\n",
       "             param_grid={&#x27;learning_rate&#x27;: [0.05, 0.1, 0.2],\n",
       "                         &#x27;max_depth&#x27;: [3, 4, 5],\n",
       "                         &#x27;n_estimators&#x27;: [100, 200, 300]},\n",
       "             scoring=&#x27;neg_mean_squared_error&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: GradientBoostingRegressor</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingRegressor()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingRegressor</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingRegressor()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=GradientBoostingRegressor(),\n",
       "             param_grid={'learning_rate': [0.05, 0.1, 0.2],\n",
       "                         'max_depth': [3, 4, 5],\n",
       "                         'n_estimators': [100, 200, 300]},\n",
       "             scoring='neg_mean_squared_error')"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scoring = 'neg_mean_squared_error'\n",
    "\n",
    "# Perform grid search cross-validation\n",
    "grid_search = GridSearchCV(estimator=gbr, param_grid=param_grid, scoring=scoring, cv=5)\n",
    "grid_search.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.2, 'max_depth': 3, 'n_estimators': 200}"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 671,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the Keras libraries and packages\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LeakyReLU,PReLU,ELU\n",
    "from keras.layers import Dropout\n",
    "from keras import regularizers\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 673,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "37/37 [==============================] - 3s 14ms/step - loss: 193528.1719 - val_loss: 191441.4062\n",
      "Epoch 2/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 154703.5000 - val_loss: 108005.1719\n",
      "Epoch 3/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 156543.0781 - val_loss: 112040.3438\n",
      "Epoch 4/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 142051.1406 - val_loss: 127432.0312\n",
      "Epoch 5/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 131246.0000 - val_loss: 119539.9844\n",
      "Epoch 6/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 123125.3828 - val_loss: 110609.4844\n",
      "Epoch 7/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 118092.4219 - val_loss: 104569.0469\n",
      "Epoch 8/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 123818.9844 - val_loss: 121245.5469\n",
      "Epoch 9/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 116080.7266 - val_loss: 118249.3828\n",
      "Epoch 10/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 116462.4688 - val_loss: 105529.2500\n",
      "Epoch 11/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 109955.3594 - val_loss: 105839.9609\n",
      "Epoch 12/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 116701.0391 - val_loss: 115304.9688\n",
      "Epoch 13/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 105312.1484 - val_loss: 119173.0938\n",
      "Epoch 14/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 105104.5938 - val_loss: 105198.5234\n",
      "Epoch 15/1000\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 106970.9688 - val_loss: 111774.9844\n",
      "Epoch 16/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 107309.5078 - val_loss: 103677.3047\n",
      "Epoch 17/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 103320.5625 - val_loss: 100644.8750\n",
      "Epoch 18/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 106144.7578 - val_loss: 106516.7344\n",
      "Epoch 19/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 102843.3594 - val_loss: 103554.4062\n",
      "Epoch 20/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 105527.9531 - val_loss: 105841.2344\n",
      "Epoch 21/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 104508.5625 - val_loss: 106233.3516\n",
      "Epoch 22/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 101435.0625 - val_loss: 92600.3359\n",
      "Epoch 23/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 99926.0859 - val_loss: 98131.6953\n",
      "Epoch 24/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 103367.1797 - val_loss: 101297.6172\n",
      "Epoch 25/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 96632.6406 - val_loss: 88592.8359\n",
      "Epoch 26/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 96930.3203 - val_loss: 86273.6250\n",
      "Epoch 27/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 100004.2188 - val_loss: 100664.8438\n",
      "Epoch 28/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 106560.6953 - val_loss: 97325.6719\n",
      "Epoch 29/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 98854.4141 - val_loss: 90859.5078\n",
      "Epoch 30/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 100011.6875 - val_loss: 103002.9531\n",
      "Epoch 31/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 100494.0078 - val_loss: 101590.6797\n",
      "Epoch 32/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 102136.5859 - val_loss: 109195.0938\n",
      "Epoch 33/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 104987.2422 - val_loss: 95906.8828\n",
      "Epoch 34/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 97330.0469 - val_loss: 100836.3359\n",
      "Epoch 35/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 99961.4766 - val_loss: 93401.7891\n",
      "Epoch 36/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 101075.5938 - val_loss: 98616.3594\n",
      "Epoch 37/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 101455.6953 - val_loss: 96130.8438\n",
      "Epoch 38/1000\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 95933.7422 - val_loss: 94467.3672\n",
      "Epoch 39/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 97516.0547 - val_loss: 97146.9609\n",
      "Epoch 40/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 95181.7188 - val_loss: 95357.3828\n",
      "Epoch 41/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 99320.5859 - val_loss: 102275.8594\n",
      "Epoch 42/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 93716.9531 - val_loss: 94290.5000\n",
      "Epoch 43/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 100285.8047 - val_loss: 92265.8359\n",
      "Epoch 44/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 98803.4922 - val_loss: 102714.5859\n",
      "Epoch 45/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 97824.5547 - val_loss: 102689.4766\n",
      "Epoch 46/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 98226.9297 - val_loss: 102008.1094\n",
      "Epoch 47/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 94018.0859 - val_loss: 95975.5859\n",
      "Epoch 48/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 97135.9844 - val_loss: 101120.7422\n",
      "Epoch 49/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 100069.5391 - val_loss: 90893.4453\n",
      "Epoch 50/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 99387.2500 - val_loss: 97883.1406\n",
      "Epoch 51/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 99476.5625 - val_loss: 96256.1016\n",
      "Epoch 52/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 97589.3438 - val_loss: 83694.4531\n",
      "Epoch 53/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 93608.6484 - val_loss: 93670.1562\n",
      "Epoch 54/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 95757.6328 - val_loss: 86603.8047\n",
      "Epoch 55/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 94959.3984 - val_loss: 94847.3984\n",
      "Epoch 56/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 96274.9922 - val_loss: 90083.6094\n",
      "Epoch 57/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 100497.0625 - val_loss: 102936.8203\n",
      "Epoch 58/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 91451.7578 - val_loss: 104520.0078\n",
      "Epoch 59/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 97640.9922 - val_loss: 91618.1797\n",
      "Epoch 60/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 98619.7891 - val_loss: 81372.6641\n",
      "Epoch 61/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 95408.6953 - val_loss: 101101.3438\n",
      "Epoch 62/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 96066.6406 - val_loss: 95391.9766\n",
      "Epoch 63/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 93826.1172 - val_loss: 97371.2344\n",
      "Epoch 64/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 95243.5000 - val_loss: 94264.5078\n",
      "Epoch 65/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 90942.3359 - val_loss: 100040.6953\n",
      "Epoch 66/1000\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 98833.6406 - val_loss: 105785.0859\n",
      "Epoch 67/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 98484.7031 - val_loss: 106814.8906\n",
      "Epoch 68/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 95951.8906 - val_loss: 99744.9688\n",
      "Epoch 69/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 98898.1562 - val_loss: 106923.6250\n",
      "Epoch 70/1000\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 93764.9609 - val_loss: 107274.0703\n",
      "Epoch 71/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 95634.4219 - val_loss: 112574.3047\n",
      "Epoch 72/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 94899.2422 - val_loss: 101869.7891\n",
      "Epoch 73/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 95220.0547 - val_loss: 99616.5938\n",
      "Epoch 74/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 96826.1328 - val_loss: 107045.8281\n",
      "Epoch 75/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 101507.2891 - val_loss: 100785.0781\n",
      "Epoch 76/1000\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 95421.1953 - val_loss: 100206.3594\n",
      "Epoch 77/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 91711.2031 - val_loss: 97523.8594\n",
      "Epoch 78/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 94092.4922 - val_loss: 101855.6172\n",
      "Epoch 79/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 91038.0781 - val_loss: 91478.9141\n",
      "Epoch 80/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 95410.2031 - val_loss: 95053.8984\n",
      "Epoch 81/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 95494.0312 - val_loss: 112053.6484\n",
      "Epoch 82/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 95948.7578 - val_loss: 98408.6094\n",
      "Epoch 83/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 90506.3125 - val_loss: 95629.4062\n",
      "Epoch 84/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 96506.0469 - val_loss: 100626.8203\n",
      "Epoch 85/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 92065.6797 - val_loss: 98265.3594\n",
      "Epoch 86/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 91963.3359 - val_loss: 86142.4688\n",
      "Epoch 87/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 93199.8828 - val_loss: 109033.7500\n",
      "Epoch 88/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 92361.7891 - val_loss: 106185.8281\n",
      "Epoch 89/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 95594.9844 - val_loss: 106172.8984\n",
      "Epoch 90/1000\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 91900.7891 - val_loss: 106998.4688\n",
      "Epoch 91/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 94169.9531 - val_loss: 100869.2734\n",
      "Epoch 92/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 97946.6406 - val_loss: 100641.1406\n",
      "Epoch 93/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 95099.2734 - val_loss: 103766.2031\n",
      "Epoch 94/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 94592.6484 - val_loss: 105893.8438\n",
      "Epoch 95/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 92284.7500 - val_loss: 105258.1016\n",
      "Epoch 96/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 96708.7109 - val_loss: 104454.2500\n",
      "Epoch 97/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 94933.0703 - val_loss: 96597.8438\n",
      "Epoch 98/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 92912.4375 - val_loss: 113826.6250\n",
      "Epoch 99/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 93639.3594 - val_loss: 105263.9531\n",
      "Epoch 100/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 88016.6562 - val_loss: 97551.5781\n",
      "Epoch 101/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 92099.4141 - val_loss: 104362.5859\n",
      "Epoch 102/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 91981.9297 - val_loss: 101094.0547\n",
      "Epoch 103/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 95135.3984 - val_loss: 102403.4922\n",
      "Epoch 104/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 90766.9141 - val_loss: 107278.3125\n",
      "Epoch 105/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 93755.5391 - val_loss: 103282.3125\n",
      "Epoch 106/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 94376.6484 - val_loss: 91591.6875\n",
      "Epoch 107/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 96315.7578 - val_loss: 106059.0781\n",
      "Epoch 108/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 96069.9688 - val_loss: 107317.3047\n",
      "Epoch 109/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 91917.7109 - val_loss: 100641.3594\n",
      "Epoch 110/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 97560.5312 - val_loss: 107843.8594\n",
      "Epoch 111/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 93587.0859 - val_loss: 109308.7656\n",
      "Epoch 112/1000\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 92168.5938 - val_loss: 107214.6953\n",
      "Epoch 113/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 92100.7812 - val_loss: 103996.1406\n",
      "Epoch 114/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 94586.6328 - val_loss: 106199.9219\n",
      "Epoch 115/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 92806.0625 - val_loss: 103989.3438\n",
      "Epoch 116/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 91011.6641 - val_loss: 97909.6406\n",
      "Epoch 117/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 94573.1406 - val_loss: 88230.3047\n",
      "Epoch 118/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 97190.7344 - val_loss: 89487.2422\n",
      "Epoch 119/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 95007.5078 - val_loss: 95651.7891\n",
      "Epoch 120/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 94775.9844 - val_loss: 84658.1562\n",
      "Epoch 121/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 93612.9375 - val_loss: 91112.2500\n",
      "Epoch 122/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 97170.4688 - val_loss: 97959.3672\n",
      "Epoch 123/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 95367.9609 - val_loss: 98970.4219\n",
      "Epoch 124/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 92978.0938 - val_loss: 90624.0312\n",
      "Epoch 125/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 91082.3594 - val_loss: 93636.3125\n",
      "Epoch 126/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 97024.8984 - val_loss: 83081.3203\n",
      "Epoch 127/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 94881.6875 - val_loss: 87165.5781\n",
      "Epoch 128/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 94316.0938 - val_loss: 103291.5000\n",
      "Epoch 129/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 91739.5859 - val_loss: 93167.4688\n",
      "Epoch 130/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 96822.4609 - val_loss: 95621.5703\n",
      "Epoch 131/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 90592.7500 - val_loss: 88193.1953\n",
      "Epoch 132/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 92148.3516 - val_loss: 88986.2578\n",
      "Epoch 133/1000\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 92648.4297 - val_loss: 104034.6328\n",
      "Epoch 134/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 92556.2500 - val_loss: 92629.7812\n",
      "Epoch 135/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 89907.3516 - val_loss: 94664.4141\n",
      "Epoch 136/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 91105.3125 - val_loss: 108790.8359\n",
      "Epoch 137/1000\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 96260.0312 - val_loss: 104923.1094\n",
      "Epoch 138/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 89093.8516 - val_loss: 95536.1406\n",
      "Epoch 139/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 91922.2188 - val_loss: 91281.5156\n",
      "Epoch 140/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 92517.4766 - val_loss: 89593.7969\n",
      "Epoch 141/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 91914.9922 - val_loss: 89710.3125\n",
      "Epoch 142/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 88544.7891 - val_loss: 101280.8594\n",
      "Epoch 143/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 92054.6562 - val_loss: 92511.8594\n",
      "Epoch 144/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 95110.6719 - val_loss: 120964.2578\n",
      "Epoch 145/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 93205.5078 - val_loss: 99755.4375\n",
      "Epoch 146/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 91609.9062 - val_loss: 95118.4141\n",
      "Epoch 147/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 90728.2031 - val_loss: 92959.5625\n",
      "Epoch 148/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 91923.2266 - val_loss: 105794.6953\n",
      "Epoch 149/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 91667.3281 - val_loss: 118577.8750\n",
      "Epoch 150/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 91473.2812 - val_loss: 89117.0625\n",
      "Epoch 151/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 89010.5859 - val_loss: 92432.9219\n",
      "Epoch 152/1000\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 94753.9219 - val_loss: 111153.5703\n",
      "Epoch 153/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 94088.6562 - val_loss: 90818.9688\n",
      "Epoch 154/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 94779.8984 - val_loss: 90220.0703\n",
      "Epoch 155/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 91141.3984 - val_loss: 99098.6016\n",
      "Epoch 156/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 93874.2031 - val_loss: 105126.0781\n",
      "Epoch 157/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 94450.6875 - val_loss: 98600.0938\n",
      "Epoch 158/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 93484.3047 - val_loss: 85488.6328\n",
      "Epoch 159/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 94639.2500 - val_loss: 90787.6562\n",
      "Epoch 160/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 90630.1875 - val_loss: 111889.7188\n",
      "Epoch 161/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 98050.8750 - val_loss: 90704.0859\n",
      "Epoch 162/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 98060.7656 - val_loss: 91315.5000\n",
      "Epoch 163/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 91780.4766 - val_loss: 89772.2812\n",
      "Epoch 164/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 92839.5781 - val_loss: 90475.3047\n",
      "Epoch 165/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 92272.9453 - val_loss: 103480.2188\n",
      "Epoch 166/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 92165.9922 - val_loss: 110040.1094\n",
      "Epoch 167/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 92630.1953 - val_loss: 102195.8047\n",
      "Epoch 168/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 97764.0156 - val_loss: 111522.0859\n",
      "Epoch 169/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 93552.1484 - val_loss: 106734.4062\n",
      "Epoch 170/1000\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 93155.8984 - val_loss: 123109.4531\n",
      "Epoch 171/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 93037.4453 - val_loss: 112934.8906\n",
      "Epoch 172/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 97067.0000 - val_loss: 115067.3047\n",
      "Epoch 173/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 94734.8281 - val_loss: 114399.7500\n",
      "Epoch 174/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 95460.5078 - val_loss: 108014.7578\n",
      "Epoch 175/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 91186.7891 - val_loss: 82609.0000\n",
      "Epoch 176/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 91440.8984 - val_loss: 103387.6953\n",
      "Epoch 177/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 91082.1406 - val_loss: 91832.2812\n",
      "Epoch 178/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 89592.7969 - val_loss: 101717.9609\n",
      "Epoch 179/1000\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 89967.3438 - val_loss: 101046.6406\n",
      "Epoch 180/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 92619.9453 - val_loss: 106799.5703\n",
      "Epoch 181/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 93075.1406 - val_loss: 95596.6797\n",
      "Epoch 182/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 91496.6094 - val_loss: 107157.7188\n",
      "Epoch 183/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 91242.4062 - val_loss: 100364.4062\n",
      "Epoch 184/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 92000.0859 - val_loss: 92094.0078\n",
      "Epoch 185/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 93618.6406 - val_loss: 113558.4609\n",
      "Epoch 186/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 89824.2109 - val_loss: 97079.1328\n",
      "Epoch 187/1000\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 89992.4609 - val_loss: 93103.7969\n",
      "Epoch 188/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 89519.7891 - val_loss: 96739.0469\n",
      "Epoch 189/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 91441.5469 - val_loss: 98567.0000\n",
      "Epoch 190/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 91608.5781 - val_loss: 109538.7500\n",
      "Epoch 191/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 91062.7109 - val_loss: 98776.9844\n",
      "Epoch 192/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 92533.5312 - val_loss: 110789.0859\n",
      "Epoch 193/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 92113.9297 - val_loss: 96155.3438\n",
      "Epoch 194/1000\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 88812.8047 - val_loss: 102115.3594\n",
      "Epoch 195/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 90756.0938 - val_loss: 108954.0469\n",
      "Epoch 196/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 93471.3906 - val_loss: 109479.4141\n",
      "Epoch 197/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 94609.6719 - val_loss: 103068.2656\n",
      "Epoch 198/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 92197.3516 - val_loss: 114129.8594\n",
      "Epoch 199/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 90123.4453 - val_loss: 107824.2656\n",
      "Epoch 200/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 91792.3594 - val_loss: 102354.5312\n",
      "Epoch 201/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 92089.4766 - val_loss: 106258.4062\n",
      "Epoch 202/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 88086.7891 - val_loss: 106184.5078\n",
      "Epoch 203/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 91703.1953 - val_loss: 101373.8516\n",
      "Epoch 204/1000\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 89805.6016 - val_loss: 95405.0391\n",
      "Epoch 205/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 91218.9766 - val_loss: 115375.0938\n",
      "Epoch 206/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 88949.6406 - val_loss: 102422.5234\n",
      "Epoch 207/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 89540.6484 - val_loss: 93425.4766\n",
      "Epoch 208/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 86618.1406 - val_loss: 111253.9141\n",
      "Epoch 209/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 90936.5938 - val_loss: 101837.5938\n",
      "Epoch 210/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 87507.7969 - val_loss: 111337.9688\n",
      "Epoch 211/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 93850.7266 - val_loss: 100976.5938\n",
      "Epoch 212/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 89465.4531 - val_loss: 108521.7422\n",
      "Epoch 213/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 90808.4688 - val_loss: 106273.8594\n",
      "Epoch 214/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 89944.7266 - val_loss: 111838.7891\n",
      "Epoch 215/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 94669.9375 - val_loss: 116568.8750\n",
      "Epoch 216/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 91341.2188 - val_loss: 109093.5391\n",
      "Epoch 217/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 90035.2031 - val_loss: 96032.0312\n",
      "Epoch 218/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 91890.3281 - val_loss: 101132.9141\n",
      "Epoch 219/1000\n",
      "37/37 [==============================] - 0s 10ms/step - loss: 90919.2109 - val_loss: 113237.1953\n",
      "Epoch 220/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 87185.7969 - val_loss: 110062.4219\n",
      "Epoch 221/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 91003.4531 - val_loss: 106151.9062\n",
      "Epoch 222/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 93788.6016 - val_loss: 118554.4219\n",
      "Epoch 223/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 88626.8125 - val_loss: 103228.1406\n",
      "Epoch 224/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 93115.6016 - val_loss: 103626.1016\n",
      "Epoch 225/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 91035.7656 - val_loss: 108807.5234\n",
      "Epoch 226/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 88487.9531 - val_loss: 105524.0859\n",
      "Epoch 227/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 86464.9531 - val_loss: 112754.8594\n",
      "Epoch 228/1000\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 89436.7578 - val_loss: 108348.9844\n",
      "Epoch 229/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 91187.6875 - val_loss: 99405.8047\n",
      "Epoch 230/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 90008.1328 - val_loss: 104162.9375\n",
      "Epoch 231/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 92220.6016 - val_loss: 115459.8047\n",
      "Epoch 232/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 85825.1406 - val_loss: 117958.1250\n",
      "Epoch 233/1000\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 93480.6484 - val_loss: 100953.9141\n",
      "Epoch 234/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 92140.8984 - val_loss: 113390.7188\n",
      "Epoch 235/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 92609.0625 - val_loss: 111523.2656\n",
      "Epoch 236/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 88340.4844 - val_loss: 105201.7109\n",
      "Epoch 237/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 91779.7344 - val_loss: 115211.7656\n",
      "Epoch 238/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 88333.1797 - val_loss: 110795.2578\n",
      "Epoch 239/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 92780.3438 - val_loss: 121451.7500\n",
      "Epoch 240/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 93707.1250 - val_loss: 115244.6875\n",
      "Epoch 241/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 90619.3594 - val_loss: 111069.2422\n",
      "Epoch 242/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 89434.0156 - val_loss: 110117.3672\n",
      "Epoch 243/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 92687.7031 - val_loss: 102318.5859\n",
      "Epoch 244/1000\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 86545.3828 - val_loss: 115286.1641\n",
      "Epoch 245/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 96342.1953 - val_loss: 106354.9531\n",
      "Epoch 246/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 91331.2188 - val_loss: 111445.4844\n",
      "Epoch 247/1000\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 86674.5859 - val_loss: 108156.5703\n",
      "Epoch 248/1000\n",
      "37/37 [==============================] - 0s 10ms/step - loss: 91311.9609 - val_loss: 112872.8672\n",
      "Epoch 249/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 88286.9922 - val_loss: 113379.7734\n",
      "Epoch 250/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 88409.3047 - val_loss: 116535.5312\n",
      "Epoch 251/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 92228.5703 - val_loss: 113394.9453\n",
      "Epoch 252/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 89635.4141 - val_loss: 103008.4453\n",
      "Epoch 253/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 91586.8594 - val_loss: 114782.6406\n",
      "Epoch 254/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 90885.1797 - val_loss: 114113.2422\n",
      "Epoch 255/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 91345.5938 - val_loss: 116767.0312\n",
      "Epoch 256/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 89833.6719 - val_loss: 107677.0781\n",
      "Epoch 257/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 92533.2344 - val_loss: 112880.9531\n",
      "Epoch 258/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 91897.7734 - val_loss: 117401.3828\n",
      "Epoch 259/1000\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 88838.4688 - val_loss: 108108.9219\n",
      "Epoch 260/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 92183.8828 - val_loss: 113332.2656\n",
      "Epoch 261/1000\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 97900.6406 - val_loss: 119196.7500\n",
      "Epoch 262/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 91449.5625 - val_loss: 115272.2734\n",
      "Epoch 263/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 90791.3594 - val_loss: 101416.3516\n",
      "Epoch 264/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 91002.6562 - val_loss: 115538.2500\n",
      "Epoch 265/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 89333.7422 - val_loss: 108787.4688\n",
      "Epoch 266/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 92308.8516 - val_loss: 103237.0859\n",
      "Epoch 267/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 85147.2656 - val_loss: 92339.1250\n",
      "Epoch 268/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 91934.7422 - val_loss: 103268.2188\n",
      "Epoch 269/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 89860.3984 - val_loss: 110275.4141\n",
      "Epoch 270/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 88407.4688 - val_loss: 112840.0312\n",
      "Epoch 271/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 90678.3438 - val_loss: 113267.2266\n",
      "Epoch 272/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 88547.0312 - val_loss: 109447.2812\n",
      "Epoch 273/1000\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 87989.4062 - val_loss: 107937.9141\n",
      "Epoch 274/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 88661.3047 - val_loss: 101288.1094\n",
      "Epoch 275/1000\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 89470.7812 - val_loss: 108942.4219\n",
      "Epoch 276/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 85819.3047 - val_loss: 96546.6406\n",
      "Epoch 277/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 95411.7031 - val_loss: 114601.0391\n",
      "Epoch 278/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 90362.7344 - val_loss: 96763.7031\n",
      "Epoch 279/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 89803.6953 - val_loss: 119428.3984\n",
      "Epoch 280/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 89634.8516 - val_loss: 109781.2734\n",
      "Epoch 281/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 91115.1094 - val_loss: 113932.8516\n",
      "Epoch 282/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 89041.5859 - val_loss: 118523.9844\n",
      "Epoch 283/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 93110.6484 - val_loss: 117834.6328\n",
      "Epoch 284/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 94606.0000 - val_loss: 122390.0938\n",
      "Epoch 285/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 84089.1562 - val_loss: 115965.4375\n",
      "Epoch 286/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 91105.8438 - val_loss: 125276.8359\n",
      "Epoch 287/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 94604.3594 - val_loss: 116423.5781\n",
      "Epoch 288/1000\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 86743.6953 - val_loss: 96217.2891\n",
      "Epoch 289/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 93467.3047 - val_loss: 115488.6562\n",
      "Epoch 290/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 87769.5625 - val_loss: 119948.8906\n",
      "Epoch 291/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 86915.5859 - val_loss: 108868.4375\n",
      "Epoch 292/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 93506.5000 - val_loss: 129100.5469\n",
      "Epoch 293/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 90834.0781 - val_loss: 112636.6797\n",
      "Epoch 294/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 89460.9141 - val_loss: 107661.7578\n",
      "Epoch 295/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 92333.7344 - val_loss: 99142.6797\n",
      "Epoch 296/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 89653.1016 - val_loss: 117996.0391\n",
      "Epoch 297/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 87830.8047 - val_loss: 108409.8594\n",
      "Epoch 298/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 92343.3828 - val_loss: 118382.9297\n",
      "Epoch 299/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 87231.1875 - val_loss: 111865.3047\n",
      "Epoch 300/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 91003.1797 - val_loss: 114697.2500\n",
      "Epoch 301/1000\n",
      "37/37 [==============================] - 0s 10ms/step - loss: 93305.4688 - val_loss: 111760.2891\n",
      "Epoch 302/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 88961.5469 - val_loss: 122879.5078\n",
      "Epoch 303/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 89668.5938 - val_loss: 113488.4922\n",
      "Epoch 304/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 92464.2500 - val_loss: 113907.8828\n",
      "Epoch 305/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 87343.0703 - val_loss: 109709.8359\n",
      "Epoch 306/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 89767.4922 - val_loss: 122472.9453\n",
      "Epoch 307/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 87526.7969 - val_loss: 100900.2891\n",
      "Epoch 308/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 90367.2188 - val_loss: 99162.1641\n",
      "Epoch 309/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 89279.7031 - val_loss: 111189.1094\n",
      "Epoch 310/1000\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 90575.9688 - val_loss: 120826.1641\n",
      "Epoch 311/1000\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 91568.6641 - val_loss: 110377.2266\n",
      "Epoch 312/1000\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 88388.7656 - val_loss: 115110.9844\n",
      "Epoch 313/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 86846.2422 - val_loss: 107550.9688\n",
      "Epoch 314/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 90432.9297 - val_loss: 98534.6641\n",
      "Epoch 315/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 86110.4141 - val_loss: 103576.3047\n",
      "Epoch 316/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 90932.5859 - val_loss: 97422.4297\n",
      "Epoch 317/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 89719.7891 - val_loss: 113488.0703\n",
      "Epoch 318/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 90015.9219 - val_loss: 118333.0000\n",
      "Epoch 319/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 92179.3281 - val_loss: 114534.2656\n",
      "Epoch 320/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 91794.1250 - val_loss: 107751.9141\n",
      "Epoch 321/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 88999.6406 - val_loss: 108215.5859\n",
      "Epoch 322/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 91527.5938 - val_loss: 114547.7500\n",
      "Epoch 323/1000\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 90206.6484 - val_loss: 119150.6719\n",
      "Epoch 324/1000\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 91492.0312 - val_loss: 107316.8203\n",
      "Epoch 325/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 86942.0703 - val_loss: 119376.3594\n",
      "Epoch 326/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 90036.3438 - val_loss: 107759.1953\n",
      "Epoch 327/1000\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 87150.7812 - val_loss: 108950.5078\n",
      "Epoch 328/1000\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 93677.3906 - val_loss: 92998.3750\n",
      "Epoch 329/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 87691.1250 - val_loss: 117845.2891\n",
      "Epoch 330/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 89149.6641 - val_loss: 99368.5312\n",
      "Epoch 331/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 89496.2266 - val_loss: 110484.4688\n",
      "Epoch 332/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 92317.3438 - val_loss: 114376.3047\n",
      "Epoch 333/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 92315.0859 - val_loss: 103102.4375\n",
      "Epoch 334/1000\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 94455.3516 - val_loss: 122453.6172\n",
      "Epoch 335/1000\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 91788.0312 - val_loss: 123598.3828\n",
      "Epoch 336/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 92917.2422 - val_loss: 117824.3047\n",
      "Epoch 337/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 92457.5469 - val_loss: 121943.5781\n",
      "Epoch 338/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 91158.8047 - val_loss: 120697.3594\n",
      "Epoch 339/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 92961.6328 - val_loss: 127544.2891\n",
      "Epoch 340/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 91731.5312 - val_loss: 124723.6016\n",
      "Epoch 341/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 89865.9609 - val_loss: 107843.8203\n",
      "Epoch 342/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 89398.3984 - val_loss: 111177.2500\n",
      "Epoch 343/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 90854.3672 - val_loss: 112405.1562\n",
      "Epoch 344/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 91594.5391 - val_loss: 114055.9531\n",
      "Epoch 345/1000\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 91545.8359 - val_loss: 122704.1953\n",
      "Epoch 346/1000\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 90153.9922 - val_loss: 112610.6875\n",
      "Epoch 347/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 87255.9141 - val_loss: 123835.3672\n",
      "Epoch 348/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 90928.4922 - val_loss: 104585.1406\n",
      "Epoch 349/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 90766.3047 - val_loss: 127887.3594\n",
      "Epoch 350/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 91299.3594 - val_loss: 111171.3594\n",
      "Epoch 351/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 90571.9766 - val_loss: 111015.5312\n",
      "Epoch 352/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 91005.6875 - val_loss: 102082.7109\n",
      "Epoch 353/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 90913.8281 - val_loss: 118378.4375\n",
      "Epoch 354/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 91465.0859 - val_loss: 116780.0000\n",
      "Epoch 355/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 91020.8047 - val_loss: 113778.6016\n",
      "Epoch 356/1000\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 90468.6250 - val_loss: 118936.7656\n",
      "Epoch 357/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 86592.2578 - val_loss: 122067.9688\n",
      "Epoch 358/1000\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 92171.4141 - val_loss: 123738.7422\n",
      "Epoch 359/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 93785.6953 - val_loss: 123527.0859\n",
      "Epoch 360/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 88512.6484 - val_loss: 112387.8594\n",
      "Epoch 361/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 93398.5312 - val_loss: 108983.8281\n",
      "Epoch 362/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 90282.5469 - val_loss: 111727.9844\n",
      "Epoch 363/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 87074.8281 - val_loss: 115282.7109\n",
      "Epoch 364/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 88952.0312 - val_loss: 107767.6172\n",
      "Epoch 365/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 85290.7891 - val_loss: 123702.6875\n",
      "Epoch 366/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 86206.2578 - val_loss: 119383.2734\n",
      "Epoch 367/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 88661.1406 - val_loss: 123734.5234\n",
      "Epoch 368/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 90144.8047 - val_loss: 119843.8516\n",
      "Epoch 369/1000\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 89978.5078 - val_loss: 114492.8984\n",
      "Epoch 370/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 85304.0000 - val_loss: 122001.6172\n",
      "Epoch 371/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 89958.3750 - val_loss: 108690.4297\n",
      "Epoch 372/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 87810.8203 - val_loss: 122397.5234\n",
      "Epoch 373/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 89495.9531 - val_loss: 115403.3594\n",
      "Epoch 374/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 90496.4375 - val_loss: 116679.0156\n",
      "Epoch 375/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 92131.1094 - val_loss: 121684.2344\n",
      "Epoch 376/1000\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 88098.4219 - val_loss: 111450.7422\n",
      "Epoch 377/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 91288.5156 - val_loss: 139380.1406\n",
      "Epoch 378/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 89613.8047 - val_loss: 123990.2344\n",
      "Epoch 379/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 89886.3047 - val_loss: 111621.2891\n",
      "Epoch 380/1000\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 93558.8672 - val_loss: 119391.7422\n",
      "Epoch 381/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 86703.0547 - val_loss: 107732.3984\n",
      "Epoch 382/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 86183.8047 - val_loss: 117049.3125\n",
      "Epoch 383/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 88249.8672 - val_loss: 112769.5781\n",
      "Epoch 384/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 93166.9609 - val_loss: 127878.9141\n",
      "Epoch 385/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 89833.4531 - val_loss: 121789.2578\n",
      "Epoch 386/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 86926.3594 - val_loss: 119293.8750\n",
      "Epoch 387/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 82578.7500 - val_loss: 119422.4141\n",
      "Epoch 388/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 84658.5781 - val_loss: 118806.6719\n",
      "Epoch 389/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 91978.9062 - val_loss: 132522.9688\n",
      "Epoch 390/1000\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 88754.3516 - val_loss: 112015.2500\n",
      "Epoch 391/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 85965.4688 - val_loss: 123745.3828\n",
      "Epoch 392/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 90217.4297 - val_loss: 118961.3594\n",
      "Epoch 393/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 89569.6094 - val_loss: 131505.5000\n",
      "Epoch 394/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 89826.6875 - val_loss: 136263.8281\n",
      "Epoch 395/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 86432.6641 - val_loss: 112002.5312\n",
      "Epoch 396/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 88633.7578 - val_loss: 128888.7500\n",
      "Epoch 397/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 88051.4141 - val_loss: 126513.7422\n",
      "Epoch 398/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 88680.4297 - val_loss: 122113.1641\n",
      "Epoch 399/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 87158.9766 - val_loss: 113638.6953\n",
      "Epoch 400/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 92332.0859 - val_loss: 121123.4375\n",
      "Epoch 401/1000\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 88604.3125 - val_loss: 108557.7578\n",
      "Epoch 402/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 88687.6953 - val_loss: 125077.2891\n",
      "Epoch 403/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 87273.6797 - val_loss: 120853.3672\n",
      "Epoch 404/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 87396.6484 - val_loss: 113720.7422\n",
      "Epoch 405/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 89176.6406 - val_loss: 127960.8047\n",
      "Epoch 406/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 86926.9531 - val_loss: 117523.4688\n",
      "Epoch 407/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 89930.2656 - val_loss: 104075.6953\n",
      "Epoch 408/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 89952.2812 - val_loss: 126080.9688\n",
      "Epoch 409/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 88851.7266 - val_loss: 116145.8906\n",
      "Epoch 410/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 87702.8828 - val_loss: 116613.0312\n",
      "Epoch 411/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 89453.7344 - val_loss: 123503.6875\n",
      "Epoch 412/1000\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 86710.5312 - val_loss: 118920.8203\n",
      "Epoch 413/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 88115.9062 - val_loss: 127809.7500\n",
      "Epoch 414/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 88975.6406 - val_loss: 114818.1094\n",
      "Epoch 415/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 93811.8984 - val_loss: 114037.3281\n",
      "Epoch 416/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 88955.5391 - val_loss: 117927.5078\n",
      "Epoch 417/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 90816.6875 - val_loss: 117750.0547\n",
      "Epoch 418/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 88753.3203 - val_loss: 109214.0703\n",
      "Epoch 419/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 87113.6094 - val_loss: 119434.5859\n",
      "Epoch 420/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 89847.7656 - val_loss: 123438.6406\n",
      "Epoch 421/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 91443.7109 - val_loss: 127453.5859\n",
      "Epoch 422/1000\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 86572.6953 - val_loss: 124883.3438\n",
      "Epoch 423/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 88678.7812 - val_loss: 120207.4531\n",
      "Epoch 424/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 90215.4688 - val_loss: 122704.9688\n",
      "Epoch 425/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 92166.2578 - val_loss: 132514.2812\n",
      "Epoch 426/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 88227.1016 - val_loss: 133017.5938\n",
      "Epoch 427/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 84602.3828 - val_loss: 122973.4688\n",
      "Epoch 428/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 88788.8906 - val_loss: 132043.4531\n",
      "Epoch 429/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 88352.4688 - val_loss: 118938.4141\n",
      "Epoch 430/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 91653.9375 - val_loss: 120812.3125\n",
      "Epoch 431/1000\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 87317.1406 - val_loss: 122065.0547\n",
      "Epoch 432/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 90411.2500 - val_loss: 117755.3125\n",
      "Epoch 433/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 87803.3047 - val_loss: 123840.4219\n",
      "Epoch 434/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 91419.0703 - val_loss: 125435.0547\n",
      "Epoch 435/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 91857.7031 - val_loss: 126768.2188\n",
      "Epoch 436/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 88973.9062 - val_loss: 125778.0547\n",
      "Epoch 437/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 89244.1719 - val_loss: 112241.7109\n",
      "Epoch 438/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 89925.9141 - val_loss: 131701.1562\n",
      "Epoch 439/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 90234.0469 - val_loss: 136494.3125\n",
      "Epoch 440/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 93074.3750 - val_loss: 123004.0859\n",
      "Epoch 441/1000\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 87347.8594 - val_loss: 115901.4375\n",
      "Epoch 442/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 91139.4844 - val_loss: 115789.3047\n",
      "Epoch 443/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 93803.2109 - val_loss: 119261.2734\n",
      "Epoch 444/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 90268.4531 - val_loss: 124051.0156\n",
      "Epoch 445/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 88868.8672 - val_loss: 122397.3984\n",
      "Epoch 446/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 88412.9688 - val_loss: 126591.2188\n",
      "Epoch 447/1000\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 91091.3047 - val_loss: 129984.1484\n",
      "Epoch 448/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 89060.4609 - val_loss: 121317.6172\n",
      "Epoch 449/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 91473.1406 - val_loss: 135366.4219\n",
      "Epoch 450/1000\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 88579.7734 - val_loss: 115236.1250\n",
      "Epoch 451/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 92391.8594 - val_loss: 122126.8594\n",
      "Epoch 452/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 87865.1875 - val_loss: 120873.0547\n",
      "Epoch 453/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 88123.1406 - val_loss: 126575.3672\n",
      "Epoch 454/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 87057.2500 - val_loss: 125522.9141\n",
      "Epoch 455/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 90590.3203 - val_loss: 133555.2344\n",
      "Epoch 456/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 87590.2422 - val_loss: 130087.5781\n",
      "Epoch 457/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 91896.5391 - val_loss: 128442.0938\n",
      "Epoch 458/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 87907.9531 - val_loss: 119285.9844\n",
      "Epoch 459/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 90950.6406 - val_loss: 119324.1797\n",
      "Epoch 460/1000\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 88720.6953 - val_loss: 121905.7266\n",
      "Epoch 461/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 88444.0234 - val_loss: 114383.4844\n",
      "Epoch 462/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 91160.0000 - val_loss: 131032.0547\n",
      "Epoch 463/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 94412.3984 - val_loss: 107557.7656\n",
      "Epoch 464/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 85787.5859 - val_loss: 110268.0078\n",
      "Epoch 465/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 86947.2656 - val_loss: 126720.4922\n",
      "Epoch 466/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 90805.6719 - val_loss: 109891.3281\n",
      "Epoch 467/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 90361.3516 - val_loss: 105050.8828\n",
      "Epoch 468/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 88516.1328 - val_loss: 107933.4766\n",
      "Epoch 469/1000\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 87349.3516 - val_loss: 115888.2891\n",
      "Epoch 470/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 87887.5078 - val_loss: 124937.0156\n",
      "Epoch 471/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 87527.5000 - val_loss: 128264.7422\n",
      "Epoch 472/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 90335.2266 - val_loss: 116033.8359\n",
      "Epoch 473/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 89499.2031 - val_loss: 123142.1250\n",
      "Epoch 474/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 87696.3906 - val_loss: 122476.4141\n",
      "Epoch 475/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 85903.9844 - val_loss: 115756.4375\n",
      "Epoch 476/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 88697.1484 - val_loss: 118460.7500\n",
      "Epoch 477/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 89518.2344 - val_loss: 109413.8438\n",
      "Epoch 478/1000\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 91913.7734 - val_loss: 119776.4219\n",
      "Epoch 479/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 85980.3906 - val_loss: 116885.3047\n",
      "Epoch 480/1000\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 86114.7031 - val_loss: 107671.5938\n",
      "Epoch 481/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 92007.8594 - val_loss: 106966.3047\n",
      "Epoch 482/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 89490.8281 - val_loss: 119400.4375\n",
      "Epoch 483/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 91205.0000 - val_loss: 125057.6172\n",
      "Epoch 484/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 88251.5625 - val_loss: 115132.8750\n",
      "Epoch 485/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 83578.8828 - val_loss: 120237.7500\n",
      "Epoch 486/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 85449.1953 - val_loss: 126185.5312\n",
      "Epoch 487/1000\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 87336.0312 - val_loss: 123335.0703\n",
      "Epoch 488/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 88402.7734 - val_loss: 119578.3984\n",
      "Epoch 489/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 88899.0859 - val_loss: 109964.9766\n",
      "Epoch 490/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 92359.8125 - val_loss: 115232.0000\n",
      "Epoch 491/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 86694.0859 - val_loss: 111418.9844\n",
      "Epoch 492/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 88054.3438 - val_loss: 120312.6016\n",
      "Epoch 493/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 90253.6484 - val_loss: 114320.8750\n",
      "Epoch 494/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 88358.6094 - val_loss: 99420.5000\n",
      "Epoch 495/1000\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 89180.1406 - val_loss: 110920.4141\n",
      "Epoch 496/1000\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 88616.9062 - val_loss: 114885.2812\n",
      "Epoch 497/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 88511.1172 - val_loss: 123536.4766\n",
      "Epoch 498/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 91940.3594 - val_loss: 131004.8750\n",
      "Epoch 499/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 88917.6406 - val_loss: 109834.5078\n",
      "Epoch 500/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 86460.5859 - val_loss: 113543.6797\n",
      "Epoch 501/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 90601.1641 - val_loss: 112922.1953\n",
      "Epoch 502/1000\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 88917.0156 - val_loss: 117384.9688\n",
      "Epoch 503/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 89164.4453 - val_loss: 116642.8594\n",
      "Epoch 504/1000\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 90633.8516 - val_loss: 116121.9062\n",
      "Epoch 505/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 86461.9062 - val_loss: 106668.9219\n",
      "Epoch 506/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 90389.5625 - val_loss: 124518.1797\n",
      "Epoch 507/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 86199.5391 - val_loss: 112201.5078\n",
      "Epoch 508/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 88203.5781 - val_loss: 125370.0312\n",
      "Epoch 509/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 85246.1875 - val_loss: 116883.4688\n",
      "Epoch 510/1000\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 91396.7578 - val_loss: 115817.5781\n",
      "Epoch 511/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 88990.3125 - val_loss: 114519.6172\n",
      "Epoch 512/1000\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 88753.3047 - val_loss: 121568.7969\n",
      "Epoch 513/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 82229.9375 - val_loss: 112984.9688\n",
      "Epoch 514/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 88070.6328 - val_loss: 113979.4922\n",
      "Epoch 515/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 84109.6953 - val_loss: 111955.4141\n",
      "Epoch 516/1000\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 86915.7031 - val_loss: 115463.6953\n",
      "Epoch 517/1000\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 90041.3750 - val_loss: 120485.9297\n",
      "Epoch 518/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 87117.4453 - val_loss: 110578.0391\n",
      "Epoch 519/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 87935.7500 - val_loss: 104427.3281\n",
      "Epoch 520/1000\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 84533.3203 - val_loss: 112852.0234\n",
      "Epoch 521/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 92439.1719 - val_loss: 115566.4141\n",
      "Epoch 522/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 89898.0078 - val_loss: 117289.9609\n",
      "Epoch 523/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 89062.7500 - val_loss: 113771.2734\n",
      "Epoch 524/1000\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 85464.2266 - val_loss: 107003.5234\n",
      "Epoch 525/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 86023.3281 - val_loss: 119512.6016\n",
      "Epoch 526/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 89125.6094 - val_loss: 118042.3828\n",
      "Epoch 527/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 88575.2969 - val_loss: 131849.9375\n",
      "Epoch 528/1000\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 88183.2422 - val_loss: 121079.8594\n",
      "Epoch 529/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 86212.0234 - val_loss: 116176.4766\n",
      "Epoch 530/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 87689.5938 - val_loss: 114575.9688\n",
      "Epoch 531/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 87484.2500 - val_loss: 104444.6406\n",
      "Epoch 532/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 93994.7266 - val_loss: 126077.6953\n",
      "Epoch 533/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 88217.4922 - val_loss: 126722.6953\n",
      "Epoch 534/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 90991.9375 - val_loss: 120158.6562\n",
      "Epoch 535/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 88789.0312 - val_loss: 111220.6172\n",
      "Epoch 536/1000\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 91280.7422 - val_loss: 119182.0703\n",
      "Epoch 537/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 85703.4453 - val_loss: 125887.8047\n",
      "Epoch 538/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 91056.6016 - val_loss: 122463.7812\n",
      "Epoch 539/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 90103.5938 - val_loss: 120639.6328\n",
      "Epoch 540/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 88228.8906 - val_loss: 128210.4922\n",
      "Epoch 541/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 89587.8281 - val_loss: 118461.6875\n",
      "Epoch 542/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 90397.3281 - val_loss: 124896.0547\n",
      "Epoch 543/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 84507.5703 - val_loss: 116766.5781\n",
      "Epoch 544/1000\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 82960.7188 - val_loss: 116253.3125\n",
      "Epoch 545/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 84660.9062 - val_loss: 109275.0625\n",
      "Epoch 546/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 89136.8047 - val_loss: 115293.5781\n",
      "Epoch 547/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 85525.8516 - val_loss: 109232.3359\n",
      "Epoch 548/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 89284.3672 - val_loss: 127401.4141\n",
      "Epoch 549/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 87249.3125 - val_loss: 120887.1797\n",
      "Epoch 550/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 90017.5156 - val_loss: 115354.9688\n",
      "Epoch 551/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 88142.7344 - val_loss: 119645.2578\n",
      "Epoch 552/1000\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 86687.9141 - val_loss: 128636.6406\n",
      "Epoch 553/1000\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 86719.8906 - val_loss: 125006.7656\n",
      "Epoch 554/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 88356.3750 - val_loss: 120358.7812\n",
      "Epoch 555/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 90606.9375 - val_loss: 118589.8047\n",
      "Epoch 556/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 87534.1484 - val_loss: 111151.6406\n",
      "Epoch 557/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 87980.8594 - val_loss: 118230.8047\n",
      "Epoch 558/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 84502.0938 - val_loss: 122955.6016\n",
      "Epoch 559/1000\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 89329.9297 - val_loss: 114855.7812\n",
      "Epoch 560/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 84152.3672 - val_loss: 118669.5859\n",
      "Epoch 561/1000\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 87667.6953 - val_loss: 110468.7188\n",
      "Epoch 562/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 84152.3594 - val_loss: 116486.4531\n",
      "Epoch 563/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 85070.9375 - val_loss: 112683.7266\n",
      "Epoch 564/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 88937.5000 - val_loss: 117809.2031\n",
      "Epoch 565/1000\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 84094.0391 - val_loss: 113663.6641\n",
      "Epoch 566/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 90233.4297 - val_loss: 117369.5312\n",
      "Epoch 567/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 88365.8203 - val_loss: 120333.1094\n",
      "Epoch 568/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 92425.6953 - val_loss: 127452.7656\n",
      "Epoch 569/1000\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 85565.5156 - val_loss: 112670.3281\n",
      "Epoch 570/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 87247.6484 - val_loss: 118600.0391\n",
      "Epoch 571/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 83797.8125 - val_loss: 121243.6953\n",
      "Epoch 572/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 86570.3750 - val_loss: 123995.5078\n",
      "Epoch 573/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 83469.6484 - val_loss: 119395.7109\n",
      "Epoch 574/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 91201.6953 - val_loss: 126279.3047\n",
      "Epoch 575/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 87025.9141 - val_loss: 122403.2344\n",
      "Epoch 576/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 89055.9141 - val_loss: 116147.5781\n",
      "Epoch 577/1000\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 89090.8047 - val_loss: 117396.8516\n",
      "Epoch 578/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 88891.4922 - val_loss: 125288.3594\n",
      "Epoch 579/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 87245.5078 - val_loss: 112634.6328\n",
      "Epoch 580/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 89517.1094 - val_loss: 116545.4688\n",
      "Epoch 581/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 91639.1172 - val_loss: 117572.9844\n",
      "Epoch 582/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 90173.5781 - val_loss: 125778.0000\n",
      "Epoch 583/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 88188.3828 - val_loss: 131213.7500\n",
      "Epoch 584/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 85214.2969 - val_loss: 114599.7656\n",
      "Epoch 585/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 89348.8203 - val_loss: 112228.8750\n",
      "Epoch 586/1000\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 85126.7891 - val_loss: 122806.0000\n",
      "Epoch 587/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 88166.7422 - val_loss: 123672.9688\n",
      "Epoch 588/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 88968.6250 - val_loss: 126596.7266\n",
      "Epoch 589/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 85812.9688 - val_loss: 116321.4766\n",
      "Epoch 590/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 87776.2656 - val_loss: 112216.2031\n",
      "Epoch 591/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 89395.7812 - val_loss: 120781.7109\n",
      "Epoch 592/1000\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 84472.5000 - val_loss: 129787.2188\n",
      "Epoch 593/1000\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 87926.1797 - val_loss: 113028.0547\n",
      "Epoch 594/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 90340.4141 - val_loss: 123711.0156\n",
      "Epoch 595/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 91186.9297 - val_loss: 125738.4375\n",
      "Epoch 596/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 86797.1875 - val_loss: 127061.4219\n",
      "Epoch 597/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 94747.8594 - val_loss: 126868.8516\n",
      "Epoch 598/1000\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 90212.4922 - val_loss: 123003.2891\n",
      "Epoch 599/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 88997.5156 - val_loss: 124688.8594\n",
      "Epoch 600/1000\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 86775.7031 - val_loss: 127748.7109\n",
      "Epoch 601/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 88375.6484 - val_loss: 122856.9141\n",
      "Epoch 602/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 88879.8281 - val_loss: 127567.2031\n",
      "Epoch 603/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 91666.0859 - val_loss: 114087.3203\n",
      "Epoch 604/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 86985.9297 - val_loss: 124533.9453\n",
      "Epoch 605/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 86223.9766 - val_loss: 113601.1250\n",
      "Epoch 606/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 86234.3906 - val_loss: 115338.0859\n",
      "Epoch 607/1000\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 87848.1250 - val_loss: 126534.7969\n",
      "Epoch 608/1000\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 87238.0859 - val_loss: 114247.9688\n",
      "Epoch 609/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 84369.0000 - val_loss: 111754.2969\n",
      "Epoch 610/1000\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 91419.6953 - val_loss: 128062.2578\n",
      "Epoch 611/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 87335.3594 - val_loss: 121293.5078\n",
      "Epoch 612/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 85411.7188 - val_loss: 111805.1875\n",
      "Epoch 613/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 86738.9922 - val_loss: 122809.9062\n",
      "Epoch 614/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 83907.1953 - val_loss: 113655.9141\n",
      "Epoch 615/1000\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 87945.8047 - val_loss: 113171.4453\n",
      "Epoch 616/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 87579.5938 - val_loss: 116061.0703\n",
      "Epoch 617/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 87311.5859 - val_loss: 117251.0938\n",
      "Epoch 618/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 85448.4766 - val_loss: 125277.7812\n",
      "Epoch 619/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 89154.5469 - val_loss: 124359.0156\n",
      "Epoch 620/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 91536.9141 - val_loss: 127673.7266\n",
      "Epoch 621/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 88202.5859 - val_loss: 123024.8750\n",
      "Epoch 622/1000\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 87426.8594 - val_loss: 117603.9844\n",
      "Epoch 623/1000\n",
      "37/37 [==============================] - 0s 10ms/step - loss: 87823.5078 - val_loss: 113388.6484\n",
      "Epoch 624/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 88552.4688 - val_loss: 117146.0000\n",
      "Epoch 625/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 88115.0859 - val_loss: 128634.4531\n",
      "Epoch 626/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 85714.6172 - val_loss: 110410.0781\n",
      "Epoch 627/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 90532.3438 - val_loss: 128898.6953\n",
      "Epoch 628/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 84844.1172 - val_loss: 123167.7109\n",
      "Epoch 629/1000\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 86734.9453 - val_loss: 124594.9453\n",
      "Epoch 630/1000\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 90303.3594 - val_loss: 119152.5859\n",
      "Epoch 631/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 83280.8750 - val_loss: 119342.2188\n",
      "Epoch 632/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 87826.8281 - val_loss: 119694.9609\n",
      "Epoch 633/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 84546.3438 - val_loss: 119899.6875\n",
      "Epoch 634/1000\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 86200.4766 - val_loss: 117992.8906\n",
      "Epoch 635/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 89453.7500 - val_loss: 115935.2031\n",
      "Epoch 636/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 90942.2734 - val_loss: 128877.4531\n",
      "Epoch 637/1000\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 88352.3672 - val_loss: 118447.2031\n",
      "Epoch 638/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 83373.3672 - val_loss: 118385.2734\n",
      "Epoch 639/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 87265.2578 - val_loss: 121331.8906\n",
      "Epoch 640/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 85194.6094 - val_loss: 131397.0000\n",
      "Epoch 641/1000\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 88698.1953 - val_loss: 127975.9297\n",
      "Epoch 642/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 89665.5781 - val_loss: 121644.0859\n",
      "Epoch 643/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 85945.5625 - val_loss: 118833.0000\n",
      "Epoch 644/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 85406.3516 - val_loss: 128248.8203\n",
      "Epoch 645/1000\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 91789.5312 - val_loss: 131614.4219\n",
      "Epoch 646/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 87823.1328 - val_loss: 134361.4219\n",
      "Epoch 647/1000\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 88424.8984 - val_loss: 119510.9141\n",
      "Epoch 648/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 88109.6094 - val_loss: 132778.5000\n",
      "Epoch 649/1000\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 84625.5859 - val_loss: 106800.1562\n",
      "Epoch 650/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 90118.3281 - val_loss: 124281.4141\n",
      "Epoch 651/1000\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 87652.4688 - val_loss: 130462.3281\n",
      "Epoch 652/1000\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 87897.0000 - val_loss: 133211.0156\n",
      "Epoch 653/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 86819.1953 - val_loss: 119257.1406\n",
      "Epoch 654/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 86011.7500 - val_loss: 129461.2734\n",
      "Epoch 655/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 84473.4688 - val_loss: 133591.9531\n",
      "Epoch 656/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 86892.6406 - val_loss: 132562.8750\n",
      "Epoch 657/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 87446.2109 - val_loss: 129817.2734\n",
      "Epoch 658/1000\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 83375.3047 - val_loss: 132718.9844\n",
      "Epoch 659/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 88449.3594 - val_loss: 135915.3906\n",
      "Epoch 660/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 84675.0938 - val_loss: 132422.6094\n",
      "Epoch 661/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 90440.4609 - val_loss: 135538.4062\n",
      "Epoch 662/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 89236.6484 - val_loss: 129786.9609\n",
      "Epoch 663/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 85426.9062 - val_loss: 125701.6719\n",
      "Epoch 664/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 87683.3359 - val_loss: 136854.8281\n",
      "Epoch 665/1000\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 86783.2969 - val_loss: 133013.8906\n",
      "Epoch 666/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 86972.6641 - val_loss: 126795.7969\n",
      "Epoch 667/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 86743.3203 - val_loss: 121719.3125\n",
      "Epoch 668/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 88305.1406 - val_loss: 126687.1797\n",
      "Epoch 669/1000\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 86707.0312 - val_loss: 130858.4141\n",
      "Epoch 670/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 86777.8750 - val_loss: 131052.9297\n",
      "Epoch 671/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 88419.3438 - val_loss: 129074.2578\n",
      "Epoch 672/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 90389.6953 - val_loss: 125134.9688\n",
      "Epoch 673/1000\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 87486.5312 - val_loss: 134173.5156\n",
      "Epoch 674/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 89399.1250 - val_loss: 124485.8047\n",
      "Epoch 675/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 82362.2188 - val_loss: 115586.1484\n",
      "Epoch 676/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 88084.7734 - val_loss: 119216.0000\n",
      "Epoch 677/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 84782.8828 - val_loss: 128663.9609\n",
      "Epoch 678/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 85129.9062 - val_loss: 135921.4219\n",
      "Epoch 679/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 88404.7500 - val_loss: 124316.7109\n",
      "Epoch 680/1000\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 87604.5078 - val_loss: 140742.2969\n",
      "Epoch 681/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 87113.2969 - val_loss: 124765.4531\n",
      "Epoch 682/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 86998.1094 - val_loss: 124530.3828\n",
      "Epoch 683/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 87161.1953 - val_loss: 122152.4688\n",
      "Epoch 684/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 86716.0469 - val_loss: 124413.1953\n",
      "Epoch 685/1000\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 87028.8828 - val_loss: 130668.0938\n",
      "Epoch 686/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 91961.3047 - val_loss: 127195.1094\n",
      "Epoch 687/1000\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 83638.6875 - val_loss: 122664.5078\n",
      "Epoch 688/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 94283.8906 - val_loss: 124811.0000\n",
      "Epoch 689/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 90194.7031 - val_loss: 115221.4531\n",
      "Epoch 690/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 88921.0859 - val_loss: 134789.2344\n",
      "Epoch 691/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 86609.5234 - val_loss: 127633.5312\n",
      "Epoch 692/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 85358.1719 - val_loss: 125866.4766\n",
      "Epoch 693/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 87161.3203 - val_loss: 127978.7422\n",
      "Epoch 694/1000\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 86651.4375 - val_loss: 122027.2188\n",
      "Epoch 695/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 87494.3047 - val_loss: 121698.8750\n",
      "Epoch 696/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 90194.9297 - val_loss: 137774.1719\n",
      "Epoch 697/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 88102.6406 - val_loss: 131126.3281\n",
      "Epoch 698/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 83393.6797 - val_loss: 126139.2344\n",
      "Epoch 699/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 86010.0312 - val_loss: 137878.1250\n",
      "Epoch 700/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 89978.3750 - val_loss: 123660.3672\n",
      "Epoch 701/1000\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 85796.2500 - val_loss: 115665.8047\n",
      "Epoch 702/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 87188.8672 - val_loss: 118938.6406\n",
      "Epoch 703/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 92254.8438 - val_loss: 129297.7422\n",
      "Epoch 704/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 85396.3047 - val_loss: 124098.8047\n",
      "Epoch 705/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 86679.1797 - val_loss: 123937.7422\n",
      "Epoch 706/1000\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 87122.1953 - val_loss: 115198.0156\n",
      "Epoch 707/1000\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 88237.7812 - val_loss: 117899.8594\n",
      "Epoch 708/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 89103.1875 - val_loss: 126397.2578\n",
      "Epoch 709/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 83610.8828 - val_loss: 126109.9688\n",
      "Epoch 710/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 85927.9922 - val_loss: 122151.0938\n",
      "Epoch 711/1000\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 89119.8594 - val_loss: 127343.6406\n",
      "Epoch 712/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 84949.9219 - val_loss: 119490.0156\n",
      "Epoch 713/1000\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 85866.9141 - val_loss: 122791.0859\n",
      "Epoch 714/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 89692.8906 - val_loss: 131222.0625\n",
      "Epoch 715/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 87192.2109 - val_loss: 121821.6016\n",
      "Epoch 716/1000\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 92207.9688 - val_loss: 122759.9844\n",
      "Epoch 717/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 86013.2734 - val_loss: 119207.3281\n",
      "Epoch 718/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 84638.3984 - val_loss: 115119.1406\n",
      "Epoch 719/1000\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 89983.3516 - val_loss: 127023.3047\n",
      "Epoch 720/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 86889.8594 - val_loss: 132568.6562\n",
      "Epoch 721/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 85207.3281 - val_loss: 121280.7812\n",
      "Epoch 722/1000\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 86677.7500 - val_loss: 127622.4688\n",
      "Epoch 723/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 88022.1562 - val_loss: 119162.7656\n",
      "Epoch 724/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 84711.6719 - val_loss: 125751.5469\n",
      "Epoch 725/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 87527.8125 - val_loss: 125476.5078\n",
      "Epoch 726/1000\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 86834.3047 - val_loss: 127238.0703\n",
      "Epoch 727/1000\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 88685.0312 - val_loss: 117858.2734\n",
      "Epoch 728/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 88413.3047 - val_loss: 128891.6562\n",
      "Epoch 729/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 87006.2891 - val_loss: 127810.7422\n",
      "Epoch 730/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 80949.0312 - val_loss: 124973.9453\n",
      "Epoch 731/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 89752.9609 - val_loss: 116523.8906\n",
      "Epoch 732/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 87602.0312 - val_loss: 126238.6016\n",
      "Epoch 733/1000\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 84914.8750 - val_loss: 123354.3594\n",
      "Epoch 734/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 86982.0703 - val_loss: 127498.6875\n",
      "Epoch 735/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 90241.2031 - val_loss: 128854.8359\n",
      "Epoch 736/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 85911.3281 - val_loss: 122969.0312\n",
      "Epoch 737/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 85777.4766 - val_loss: 128851.3281\n",
      "Epoch 738/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 84790.4688 - val_loss: 120489.1406\n",
      "Epoch 739/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 89012.4922 - val_loss: 109416.0391\n",
      "Epoch 740/1000\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 84067.8203 - val_loss: 119546.4766\n",
      "Epoch 741/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 91271.0312 - val_loss: 121285.1406\n",
      "Epoch 742/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 84513.8359 - val_loss: 119528.7656\n",
      "Epoch 743/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 85587.2422 - val_loss: 125740.9844\n",
      "Epoch 744/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 88367.9141 - val_loss: 117402.3047\n",
      "Epoch 745/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 87169.4766 - val_loss: 129608.8359\n",
      "Epoch 746/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 89111.3984 - val_loss: 141276.7188\n",
      "Epoch 747/1000\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 85963.0781 - val_loss: 129751.7500\n",
      "Epoch 748/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 84354.0000 - val_loss: 129369.3984\n",
      "Epoch 749/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 88361.7969 - val_loss: 119173.7422\n",
      "Epoch 750/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 83575.4766 - val_loss: 134433.3750\n",
      "Epoch 751/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 88616.5000 - val_loss: 130033.6328\n",
      "Epoch 752/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 85972.4141 - val_loss: 107268.2500\n",
      "Epoch 753/1000\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 90609.8594 - val_loss: 125842.3672\n",
      "Epoch 754/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 82390.4297 - val_loss: 123457.8203\n",
      "Epoch 755/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 84820.5547 - val_loss: 119051.7266\n",
      "Epoch 756/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 87152.2969 - val_loss: 129025.3125\n",
      "Epoch 757/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 87268.1562 - val_loss: 130149.2891\n",
      "Epoch 758/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 83970.5078 - val_loss: 125548.1641\n",
      "Epoch 759/1000\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 86817.6328 - val_loss: 126346.5312\n",
      "Epoch 760/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 85321.7422 - val_loss: 130804.0312\n",
      "Epoch 761/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 85078.0000 - val_loss: 119750.5078\n",
      "Epoch 762/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 92009.4531 - val_loss: 127922.7500\n",
      "Epoch 763/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 86881.6953 - val_loss: 126280.0391\n",
      "Epoch 764/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 87837.5547 - val_loss: 130858.3281\n",
      "Epoch 765/1000\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 85002.0234 - val_loss: 129669.1094\n",
      "Epoch 766/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 88168.0312 - val_loss: 125253.0391\n",
      "Epoch 767/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 84265.9844 - val_loss: 120090.4766\n",
      "Epoch 768/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 87997.9844 - val_loss: 127654.2578\n",
      "Epoch 769/1000\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 83580.3594 - val_loss: 113642.5078\n",
      "Epoch 770/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 90890.6562 - val_loss: 124920.2188\n",
      "Epoch 771/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 87073.3594 - val_loss: 114604.7031\n",
      "Epoch 772/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 86416.3516 - val_loss: 125000.2344\n",
      "Epoch 773/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 86819.9766 - val_loss: 125271.6328\n",
      "Epoch 774/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 87729.6094 - val_loss: 130642.6953\n",
      "Epoch 775/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 88134.3281 - val_loss: 128134.6172\n",
      "Epoch 776/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 88883.8047 - val_loss: 134831.3125\n",
      "Epoch 777/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 86200.1016 - val_loss: 134817.5781\n",
      "Epoch 778/1000\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 82814.2500 - val_loss: 122978.4141\n",
      "Epoch 779/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 87961.6406 - val_loss: 112483.0469\n",
      "Epoch 780/1000\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 89050.1953 - val_loss: 130896.4531\n",
      "Epoch 781/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 88993.1797 - val_loss: 131698.6562\n",
      "Epoch 782/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 83825.8906 - val_loss: 123851.1953\n",
      "Epoch 783/1000\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 80440.1953 - val_loss: 130583.9844\n",
      "Epoch 784/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 87308.0000 - val_loss: 127869.2734\n",
      "Epoch 785/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 88220.9688 - val_loss: 123417.0391\n",
      "Epoch 786/1000\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 86713.6016 - val_loss: 130784.8750\n",
      "Epoch 787/1000\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 85904.6953 - val_loss: 124298.4531\n",
      "Epoch 788/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 93394.0859 - val_loss: 116263.3125\n",
      "Epoch 789/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 84020.3047 - val_loss: 123168.6172\n",
      "Epoch 790/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 90275.6172 - val_loss: 120733.9688\n",
      "Epoch 791/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 88886.5859 - val_loss: 124844.3047\n",
      "Epoch 792/1000\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 88997.2031 - val_loss: 127731.4141\n",
      "Epoch 793/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 89022.2891 - val_loss: 129324.9062\n",
      "Epoch 794/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 85347.9375 - val_loss: 120995.5234\n",
      "Epoch 795/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 90143.6953 - val_loss: 136332.7188\n",
      "Epoch 796/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 87748.9688 - val_loss: 125313.3672\n",
      "Epoch 797/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 88746.3438 - val_loss: 134969.6094\n",
      "Epoch 798/1000\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 87314.8906 - val_loss: 134454.6875\n",
      "Epoch 799/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 87709.1250 - val_loss: 125299.2891\n",
      "Epoch 800/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 88384.0156 - val_loss: 134548.7656\n",
      "Epoch 801/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 86719.7031 - val_loss: 131012.9609\n",
      "Epoch 802/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 85021.0000 - val_loss: 121417.4922\n",
      "Epoch 803/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 86427.2031 - val_loss: 129603.6719\n",
      "Epoch 804/1000\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 87898.0000 - val_loss: 128997.5625\n",
      "Epoch 805/1000\n",
      "37/37 [==============================] - 0s 10ms/step - loss: 86341.4844 - val_loss: 121235.3828\n",
      "Epoch 806/1000\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 89852.8594 - val_loss: 118869.7266\n",
      "Epoch 807/1000\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 83723.7031 - val_loss: 134979.7188\n",
      "Epoch 808/1000\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 85909.0938 - val_loss: 133297.2188\n",
      "Epoch 809/1000\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 86460.6406 - val_loss: 130965.0703\n",
      "Epoch 810/1000\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 87635.8594 - val_loss: 123849.7266\n",
      "Epoch 811/1000\n",
      "37/37 [==============================] - 0s 10ms/step - loss: 86514.9141 - val_loss: 125280.3438\n",
      "Epoch 812/1000\n",
      "37/37 [==============================] - 0s 10ms/step - loss: 84388.2969 - val_loss: 120425.9453\n",
      "Epoch 813/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 90233.6250 - val_loss: 125315.1797\n",
      "Epoch 814/1000\n",
      "37/37 [==============================] - 0s 10ms/step - loss: 90238.8125 - val_loss: 132251.1562\n",
      "Epoch 815/1000\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 86803.7578 - val_loss: 121279.9453\n",
      "Epoch 816/1000\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 81939.0234 - val_loss: 124712.4531\n",
      "Epoch 817/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 87733.5703 - val_loss: 129404.4141\n",
      "Epoch 818/1000\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 84163.4062 - val_loss: 125343.4141\n",
      "Epoch 819/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 89337.3047 - val_loss: 127231.8047\n",
      "Epoch 820/1000\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 83992.8359 - val_loss: 121574.9297\n",
      "Epoch 821/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 89489.9609 - val_loss: 127864.8516\n",
      "Epoch 822/1000\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 83408.0156 - val_loss: 123243.8594\n",
      "Epoch 823/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 89195.2344 - val_loss: 126613.0859\n",
      "Epoch 824/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 89591.3438 - val_loss: 135200.6094\n",
      "Epoch 825/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 85081.2969 - val_loss: 119313.3984\n",
      "Epoch 826/1000\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 90596.9922 - val_loss: 135824.7188\n",
      "Epoch 827/1000\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 83490.3438 - val_loss: 128219.8203\n",
      "Epoch 828/1000\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 86010.6016 - val_loss: 118538.6172\n",
      "Epoch 829/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 90405.0469 - val_loss: 132608.4219\n",
      "Epoch 830/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 84087.5859 - val_loss: 121392.3594\n",
      "Epoch 831/1000\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 85081.8047 - val_loss: 128656.7266\n",
      "Epoch 832/1000\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 87827.5859 - val_loss: 129526.1484\n",
      "Epoch 833/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 90876.5781 - val_loss: 130252.2188\n",
      "Epoch 834/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 91309.4141 - val_loss: 133470.4062\n",
      "Epoch 835/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 83218.6875 - val_loss: 127859.6172\n",
      "Epoch 836/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 86485.8594 - val_loss: 128845.0312\n",
      "Epoch 837/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 86676.1562 - val_loss: 137951.0156\n",
      "Epoch 838/1000\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 87711.1250 - val_loss: 141516.1562\n",
      "Epoch 839/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 88270.7500 - val_loss: 121581.4922\n",
      "Epoch 840/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 85888.3828 - val_loss: 135753.8906\n",
      "Epoch 841/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 88204.3438 - val_loss: 129684.5781\n",
      "Epoch 842/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 83950.5078 - val_loss: 123631.7500\n",
      "Epoch 843/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 84782.8281 - val_loss: 137156.5312\n",
      "Epoch 844/1000\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 88859.1406 - val_loss: 121800.4219\n",
      "Epoch 845/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 89071.1172 - val_loss: 134296.8125\n",
      "Epoch 846/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 86150.7422 - val_loss: 128966.1484\n",
      "Epoch 847/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 84865.6016 - val_loss: 127278.3281\n",
      "Epoch 848/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 85960.3125 - val_loss: 132856.2969\n",
      "Epoch 849/1000\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 83543.3281 - val_loss: 122713.6562\n",
      "Epoch 850/1000\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 86870.8672 - val_loss: 122906.7812\n",
      "Epoch 851/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 87353.8047 - val_loss: 119783.8594\n",
      "Epoch 852/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 89291.3828 - val_loss: 131673.6562\n",
      "Epoch 853/1000\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 87832.9141 - val_loss: 121849.9141\n",
      "Epoch 854/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 86963.4844 - val_loss: 121812.8750\n",
      "Epoch 855/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 86224.5312 - val_loss: 122950.9062\n",
      "Epoch 856/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 86848.3047 - val_loss: 126118.2344\n",
      "Epoch 857/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 88373.7500 - val_loss: 132695.4531\n",
      "Epoch 858/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 83500.3828 - val_loss: 127014.1484\n",
      "Epoch 859/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 89425.8672 - val_loss: 128352.5312\n",
      "Epoch 860/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 87341.1484 - val_loss: 128627.4141\n",
      "Epoch 861/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 86070.6875 - val_loss: 131865.5938\n",
      "Epoch 862/1000\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 84513.0703 - val_loss: 111255.1406\n",
      "Epoch 863/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 85941.2422 - val_loss: 122427.5078\n",
      "Epoch 864/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 80843.5312 - val_loss: 128074.6328\n",
      "Epoch 865/1000\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 87435.8672 - val_loss: 125736.2578\n",
      "Epoch 866/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 84795.4688 - val_loss: 132076.4844\n",
      "Epoch 867/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 86310.2578 - val_loss: 125320.4922\n",
      "Epoch 868/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 85744.9531 - val_loss: 131046.2344\n",
      "Epoch 869/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 87063.6953 - val_loss: 129089.3281\n",
      "Epoch 870/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 88748.8672 - val_loss: 144201.4375\n",
      "Epoch 871/1000\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 86187.9375 - val_loss: 134800.7500\n",
      "Epoch 872/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 86566.8672 - val_loss: 127387.7656\n",
      "Epoch 873/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 90688.8047 - val_loss: 135135.6094\n",
      "Epoch 874/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 87292.7500 - val_loss: 130866.6406\n",
      "Epoch 875/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 90856.7656 - val_loss: 132030.6094\n",
      "Epoch 876/1000\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 85649.0000 - val_loss: 128309.8047\n",
      "Epoch 877/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 86606.2891 - val_loss: 126346.4219\n",
      "Epoch 878/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 88364.4219 - val_loss: 127614.5859\n",
      "Epoch 879/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 83348.6641 - val_loss: 129447.0547\n",
      "Epoch 880/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 90522.4375 - val_loss: 130673.0391\n",
      "Epoch 881/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 81517.2812 - val_loss: 126040.2031\n",
      "Epoch 882/1000\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 89501.3516 - val_loss: 137843.7812\n",
      "Epoch 883/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 86442.7188 - val_loss: 121794.4531\n",
      "Epoch 884/1000\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 86613.3984 - val_loss: 129702.3125\n",
      "Epoch 885/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 84130.6484 - val_loss: 131811.4844\n",
      "Epoch 886/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 89974.2812 - val_loss: 131372.2812\n",
      "Epoch 887/1000\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 84699.9219 - val_loss: 123932.4219\n",
      "Epoch 888/1000\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 84654.4297 - val_loss: 127135.0391\n",
      "Epoch 889/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 87476.1562 - val_loss: 130497.3828\n",
      "Epoch 890/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 86929.9141 - val_loss: 138697.2031\n",
      "Epoch 891/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 85938.7109 - val_loss: 134493.7031\n",
      "Epoch 892/1000\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 87123.6328 - val_loss: 131340.0000\n",
      "Epoch 893/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 80964.0234 - val_loss: 127062.2734\n",
      "Epoch 894/1000\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 83636.0234 - val_loss: 120536.9609\n",
      "Epoch 895/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 89941.3203 - val_loss: 126329.6016\n",
      "Epoch 896/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 86403.7734 - val_loss: 118162.9844\n",
      "Epoch 897/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 88921.5625 - val_loss: 139869.1250\n",
      "Epoch 898/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 90952.9219 - val_loss: 130717.3984\n",
      "Epoch 899/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 85124.5391 - val_loss: 125338.4766\n",
      "Epoch 900/1000\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 83267.3047 - val_loss: 129368.2344\n",
      "Epoch 901/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 85792.0000 - val_loss: 125006.7656\n",
      "Epoch 902/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 90730.7891 - val_loss: 126707.0312\n",
      "Epoch 903/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 86332.2500 - val_loss: 123423.2344\n",
      "Epoch 904/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 92667.4922 - val_loss: 133356.5000\n",
      "Epoch 905/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 88831.2734 - val_loss: 129669.8203\n",
      "Epoch 906/1000\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 86266.3047 - val_loss: 126525.9688\n",
      "Epoch 907/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 88210.3047 - val_loss: 130326.7812\n",
      "Epoch 908/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 90110.0391 - val_loss: 134277.7344\n",
      "Epoch 909/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 88059.5078 - val_loss: 126315.7812\n",
      "Epoch 910/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 87903.6406 - val_loss: 127420.9297\n",
      "Epoch 911/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 87201.3125 - val_loss: 124339.4922\n",
      "Epoch 912/1000\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 85659.1875 - val_loss: 132171.3906\n",
      "Epoch 913/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 88147.3047 - val_loss: 121374.3125\n",
      "Epoch 914/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 85522.6094 - val_loss: 131183.6250\n",
      "Epoch 915/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 87437.0234 - val_loss: 123217.6953\n",
      "Epoch 916/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 87327.8906 - val_loss: 131483.8281\n",
      "Epoch 917/1000\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 84142.7734 - val_loss: 126007.7500\n",
      "Epoch 918/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 85136.4062 - val_loss: 131028.6406\n",
      "Epoch 919/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 90388.2734 - val_loss: 134035.1875\n",
      "Epoch 920/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 86414.3047 - val_loss: 127154.2188\n",
      "Epoch 921/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 85326.8125 - val_loss: 132210.2188\n",
      "Epoch 922/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 91090.3828 - val_loss: 146063.3750\n",
      "Epoch 923/1000\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 90536.2969 - val_loss: 139578.0781\n",
      "Epoch 924/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 85625.2266 - val_loss: 132742.7344\n",
      "Epoch 925/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 86477.5000 - val_loss: 129109.6016\n",
      "Epoch 926/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 86395.6016 - val_loss: 135800.7812\n",
      "Epoch 927/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 86390.6953 - val_loss: 132704.8281\n",
      "Epoch 928/1000\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 86173.0156 - val_loss: 134139.2344\n",
      "Epoch 929/1000\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 86153.9766 - val_loss: 133536.7812\n",
      "Epoch 930/1000\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 84328.0703 - val_loss: 129883.4922\n",
      "Epoch 931/1000\n",
      "37/37 [==============================] - 0s 10ms/step - loss: 87601.8359 - val_loss: 137834.8281\n",
      "Epoch 932/1000\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 86896.2812 - val_loss: 129240.2500\n",
      "Epoch 933/1000\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 87393.0703 - val_loss: 132704.5781\n",
      "Epoch 934/1000\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 85356.2109 - val_loss: 130916.2344\n",
      "Epoch 935/1000\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 87287.4141 - val_loss: 135385.6250\n",
      "Epoch 936/1000\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 87502.9531 - val_loss: 122030.0391\n",
      "Epoch 937/1000\n",
      "37/37 [==============================] - 0s 10ms/step - loss: 87321.3516 - val_loss: 124427.6953\n",
      "Epoch 938/1000\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 86526.3594 - val_loss: 132713.0781\n",
      "Epoch 939/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 83879.4844 - val_loss: 118418.7109\n",
      "Epoch 940/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 88661.6953 - val_loss: 127397.8516\n",
      "Epoch 941/1000\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 83196.7500 - val_loss: 134755.1406\n",
      "Epoch 942/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 86546.2344 - val_loss: 126804.8750\n",
      "Epoch 943/1000\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 82120.0859 - val_loss: 132294.9219\n",
      "Epoch 944/1000\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 83978.1094 - val_loss: 135600.3750\n",
      "Epoch 945/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 90062.4453 - val_loss: 131993.4375\n",
      "Epoch 946/1000\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 82807.3359 - val_loss: 126842.7656\n",
      "Epoch 947/1000\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 87998.5078 - val_loss: 123645.2500\n",
      "Epoch 948/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 86306.6797 - val_loss: 116629.2031\n",
      "Epoch 949/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 86121.4609 - val_loss: 122181.6953\n",
      "Epoch 950/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 83532.6250 - val_loss: 123898.1797\n",
      "Epoch 951/1000\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 84133.2578 - val_loss: 127849.8750\n",
      "Epoch 952/1000\n",
      "37/37 [==============================] - 0s 10ms/step - loss: 85590.4062 - val_loss: 127475.8594\n",
      "Epoch 953/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 85988.1406 - val_loss: 125754.1250\n",
      "Epoch 954/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 80964.6797 - val_loss: 127006.9844\n",
      "Epoch 955/1000\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 87008.0078 - val_loss: 128497.5859\n",
      "Epoch 956/1000\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 88005.7109 - val_loss: 119543.5234\n",
      "Epoch 957/1000\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 86573.0078 - val_loss: 128143.1406\n",
      "Epoch 958/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 87203.2812 - val_loss: 122762.4375\n",
      "Epoch 959/1000\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 87394.1250 - val_loss: 130731.6172\n",
      "Epoch 960/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 87323.2500 - val_loss: 136555.6094\n",
      "Epoch 961/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 85557.5781 - val_loss: 136872.9531\n",
      "Epoch 962/1000\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 82095.4062 - val_loss: 136035.3906\n",
      "Epoch 963/1000\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 87184.8594 - val_loss: 124732.4219\n",
      "Epoch 964/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 85458.2188 - val_loss: 135191.8125\n",
      "Epoch 965/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 84462.1172 - val_loss: 122917.8516\n",
      "Epoch 966/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 79709.5000 - val_loss: 127052.3281\n",
      "Epoch 967/1000\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 82962.8359 - val_loss: 129527.4922\n",
      "Epoch 968/1000\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 83383.8047 - val_loss: 121167.2188\n",
      "Epoch 969/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 83382.6797 - val_loss: 127188.7500\n",
      "Epoch 970/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 80633.4688 - val_loss: 126597.8906\n",
      "Epoch 971/1000\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 87566.8828 - val_loss: 121582.5234\n",
      "Epoch 972/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 84638.8750 - val_loss: 131980.6406\n",
      "Epoch 973/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 86663.3672 - val_loss: 127230.7812\n",
      "Epoch 974/1000\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 86546.4062 - val_loss: 117941.5625\n",
      "Epoch 975/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 85199.9375 - val_loss: 129429.1406\n",
      "Epoch 976/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 84069.3984 - val_loss: 139046.2969\n",
      "Epoch 977/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 83262.3750 - val_loss: 131775.9844\n",
      "Epoch 978/1000\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 90148.3516 - val_loss: 128753.3047\n",
      "Epoch 979/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 86755.1797 - val_loss: 127616.2031\n",
      "Epoch 980/1000\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 85287.3047 - val_loss: 123103.1094\n",
      "Epoch 981/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 88156.2266 - val_loss: 127532.0703\n",
      "Epoch 982/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 85597.8281 - val_loss: 130401.8594\n",
      "Epoch 983/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 81410.3125 - val_loss: 131915.8281\n",
      "Epoch 984/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 89502.6328 - val_loss: 130878.6953\n",
      "Epoch 985/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 88159.3203 - val_loss: 134630.2188\n",
      "Epoch 986/1000\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 87770.2500 - val_loss: 133989.6562\n",
      "Epoch 987/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 85455.0000 - val_loss: 130506.0703\n",
      "Epoch 988/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 85586.1406 - val_loss: 124977.6953\n",
      "Epoch 989/1000\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 87168.7734 - val_loss: 125476.2734\n",
      "Epoch 990/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 85392.3906 - val_loss: 128781.8359\n",
      "Epoch 991/1000\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 85716.3359 - val_loss: 123536.6172\n",
      "Epoch 992/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 84969.3047 - val_loss: 131013.7422\n",
      "Epoch 993/1000\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 85570.3438 - val_loss: 123536.9844\n",
      "Epoch 994/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 82441.5156 - val_loss: 123265.9297\n",
      "Epoch 995/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 87374.4688 - val_loss: 129745.0156\n",
      "Epoch 996/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 84784.9453 - val_loss: 129914.9844\n",
      "Epoch 997/1000\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 86138.7031 - val_loss: 121079.6953\n",
      "Epoch 998/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 89221.6875 - val_loss: 128145.2578\n",
      "Epoch 999/1000\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 83992.2344 - val_loss: 123129.5625\n",
      "Epoch 1000/1000\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 83176.7734 - val_loss: 119405.9062\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "# Define custom RMSE metric\n",
    "def root_mean_squared_error(y_true, y_pred):\n",
    "    return K.sqrt(K.mean(K.square(y_pred - y_true)))\n",
    "\n",
    "# Initialize the classifier\n",
    "classifier = Sequential()\n",
    "\n",
    "# Adding layers to the neural network\n",
    "classifier.add(Dense(units=128, activation='relu', input_dim=175,kernel_regularizer=regularizers.l2(0.01)))\n",
    "classifier.add(Dropout(0.5))\n",
    "classifier.add(Dense(units=64, activation='relu',kernel_regularizer=regularizers.l2(0.01)))\n",
    "classifier.add(Dropout(0.5))\n",
    "classifier.add(Dense(units=64, activation='relu',kernel_regularizer=regularizers.l2(0.01)))\n",
    "classifier.add(Dropout(0.5))\n",
    "classifier.add(Dense(units=32, activation='relu',kernel_regularizer=regularizers.l2(0.01)))\n",
    "classifier.add(Dropout(0.5))\n",
    "classifier.add(Dense(units=32, activation='relu',kernel_regularizer=regularizers.l2(0.01)))\n",
    "classifier.add(Dropout(0.5))\n",
    "classifier.add(Dense(units=16, activation='relu',kernel_regularizer=regularizers.l2(0.01)))\n",
    "classifier.add(Dropout(0.5))\n",
    "\n",
    "classifier.add(Dense(units=1))\n",
    "\n",
    "# Compiling the ANN\n",
    "classifier.compile(loss=root_mean_squared_error, optimizer='Adam')\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Convert input data to NumPy arrays\n",
    "x_train_np = np.array(x_train.values, dtype=np.float32)\n",
    "y_train_np = np.array(y_train.values, dtype=np.float32)\n",
    "\n",
    "# Fitting the ANN to the Training set\n",
    "model_history = classifier.fit(x_train_np, y_train_np, validation_split=0.20, batch_size=32, epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 674,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_np = np.array(df_Test.values, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 676,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "ypred8=classifier.predict(x_test_np)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
